{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c013f2-fb34-4e45-8377-c3a8fe0710e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d58aec1-6e5f-4509-a73c-29c8d0bde45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\Tanishq\\\\Downloads\\\\Data.csv\")\n",
    "x = data.iloc[:, 0].to_numpy()\n",
    "y = data.iloc[:, 1].to_numpy()\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, random_state = 1, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "353b9fe4-825b-458f-b05a-ed8446b64bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, x, y):\n",
    "        self.w = 0\n",
    "        self.b = 0\n",
    "        self.pred_y = []\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def grad_d(self, w, b, pred_y, x, y):\n",
    "        summation_loss_w = 0\n",
    "        summation_loss_b = 0`\n",
    "        print(len(pred_y))\n",
    "        for i in range(len(pred_y)):\n",
    "            loss = pred_y[i] - self.y[i]\n",
    "            loss_n_w = loss * 2*self.x[i]\n",
    "            loss_n_b = loss * 2\n",
    "            summation_loss_w+=loss_n_w\n",
    "            summation_loss_b+=loss_n_b\n",
    "        w_deri = summation_loss_w / len(pred_y)\n",
    "        b_deri = summation_loss_b / len(pred_y)\n",
    "        \n",
    "        learning_rate = 0.01\n",
    "        \n",
    "        new_w = w - (learning_rate * w_deri)\n",
    "        new_b = b - (learning_rate * b_deri)\n",
    "        return new_w, new_b\n",
    "\n",
    "    def r2_score(self):\n",
    "        y_mean = sum(self.y) / len(self.y)\n",
    "        ss_total = sum((yi - y_mean)**2 for yi in self.y)\n",
    "        ss_res = sum((self.w * self.x[i] + self.b - self.y[i])**2 for i in range(len(self.y)))\n",
    "        return 1 - (ss_res / ss_total)\n",
    "\n",
    "\n",
    "    def mse(self):\n",
    "        error = 0\n",
    "        for i in range(len(self.y)):\n",
    "            error += (self.w * self.x[i] + self.b - self.y[i])**2\n",
    "        return error / len(self.y)\n",
    "\n",
    "    \n",
    "    def model(self, epochs = 100):\n",
    "        self.w = 0\n",
    "        self.b = 0\n",
    "        #output\n",
    "        for j in range(epochs):\n",
    "            for i in range(len(self.x)):\n",
    "                pred = self.w * self.x[i] + self.b\n",
    "                self.pred_y.append(pred)\n",
    "            self.w, self.b = self.grad_d(self.w, self.b, self.pred_y, self.x, self.y)\n",
    "            print(f\"Accuracy = {self.r2_score()}, loss = {self.mse()}\")\n",
    "            self.pred_y = []\n",
    "        return self.r2_score()\n",
    "\n",
    "    \n",
    "    \n",
    "    def predict(self, x):\n",
    "        predicted = []\n",
    "        for i in x:\n",
    "            ans = self.w * i + self.b\n",
    "            predicted.append(ans)\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62cc00a4-2cef-4658-a8d8-cc9ab012d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = LinearRegression(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5c1732e-d373-4761-9de2-9b7b216d3020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "Accuracy = -1.7551984986682028, loss = 85.51728697898452\n",
      "80\n",
      "Accuracy = -1.57218426172812, loss = 79.83679570795262\n",
      "80\n",
      "Accuracy = -1.4024257096985804, loss = 74.5677412938825\n",
      "80\n",
      "Accuracy = -1.2449543676955241, loss = 69.68006370856494\n",
      "80\n",
      "Accuracy = -1.0988725800325305, loss = 65.14590104695712\n",
      "80\n",
      "Accuracy = -0.9633483311595838, loss = 60.939428776780844\n",
      "80\n",
      "Accuracy = -0.8376104453537268, loss = 57.03671074401918\n",
      "80\n",
      "Accuracy = -0.7209441374629324, loss = 53.41556107458583\n",
      "80\n",
      "Accuracy = -0.6126868890301636, loss = 50.05541617531438\n",
      "80\n",
      "Accuracy = -0.5122246260020908, loss = 46.93721609568936\n",
      "80\n",
      "Accuracy = -0.4189881759671641, loss = 44.04329456575506\n",
      "80\n",
      "Accuracy = -0.33244998448064766, loss = 41.35727707570054\n",
      "80\n",
      "Accuracy = -0.2521210715292066, loss = 38.863986409021244\n",
      "80\n",
      "Accuracy = -0.17754821057331482, loss = 36.54935508416696\n",
      "80\n",
      "Accuracy = -0.10831131389002668, loss = 34.40034419944809\n",
      "80\n",
      "Accuracy = -0.04402100912908957, loss = 32.404868212921166\n",
      "80\n",
      "Accuracy = 0.01568360690132331, loss = 30.551725223219734\n",
      "80\n",
      "Accuracy = 0.0711370501803048, loss = 28.83053234903888\n",
      "80\n",
      "Accuracy = 0.122649379164535, loss = 27.231665834401316\n",
      "80\n",
      "Accuracy = 0.17050798335787964, loss = 25.746205534102\n",
      "80\n",
      "Accuracy = 0.21497924108062827, loss = 24.365883459002518\n",
      "80\n",
      "Accuracy = 0.25631005600398904, loss = 23.083036084272592\n",
      "80\n",
      "Accuracy = 0.2947292813159125, loss = 21.890560145389003\n",
      "80\n",
      "Accuracy = 0.3304490397359173, loss = 20.781871666827435\n",
      "80\n",
      "Accuracy = 0.3636659469956409, loss = 19.750867987035512\n",
      "80\n",
      "Accuracy = 0.3945622458447948, loss = 18.79189256056489\n",
      "80\n",
      "Accuracy = 0.4233068571259323, loss = 17.899702334264823\n",
      "80\n",
      "Accuracy = 0.45005635398290456, loss = 17.069437509292364\n",
      "80\n",
      "Accuracy = 0.4749558648243447, loss = 16.296593514461122\n",
      "80\n",
      "Accuracy = 0.49813991025243065, loss = 15.576995029210133\n",
      "80\n",
      "Accuracy = 0.5197331787861337, loss = 14.906771906301364\n",
      "80\n",
      "Accuracy = 0.5398512458550015, loss = 14.282336855315943\n",
      "80\n",
      "Accuracy = 0.5586012402121823, loss = 13.70036475817941\n",
      "80\n",
      "Accuracy = 0.5760824616119904, loss = 13.157773497363474\n",
      "80\n",
      "Accuracy = 0.5923869533161126, loss = 12.651706186140029\n",
      "80\n",
      "Accuracy = 0.607600032731892, loss = 12.179514698353518\n",
      "80\n",
      "Accuracy = 0.6218007832445579, loss = 11.738744402675865\n",
      "80\n",
      "Accuracy = 0.6350625100813339, loss = 11.327120013258673\n",
      "80\n",
      "Accuracy = 0.6474531628378277, loss = 10.94253247513892\n",
      "80\n",
      "Accuracy = 0.6590357271047389, loss = 10.583026808725133\n",
      "80\n",
      "Accuracy = 0.6698685874546118, loss = 10.246790843225321\n",
      "80\n",
      "Accuracy = 0.6800058638831232, loss = 9.93214477400695\n",
      "80\n",
      "Accuracy = 0.6894977236462041, loss = 9.63753148363385\n",
      "80\n",
      "Accuracy = 0.6983906702923359, loss = 9.361507570731145\n",
      "80\n",
      "Accuracy = 0.7067278115577651, loss = 9.102735034913975\n",
      "80\n",
      "Accuracy = 0.7145491076704238, loss = 8.859973569800966\n",
      "80\n",
      "Accuracy = 0.7218916014952917, loss = 8.632073419642577\n",
      "80\n",
      "Accuracy = 0.7287896318491591, loss = 8.41796875834628\n",
      "80\n",
      "Accuracy = 0.7352750312156349, loss = 8.216671552695098\n",
      "80\n",
      "Accuracy = 0.7413773090012337, loss = 8.027265874349679\n",
      "80\n",
      "Accuracy = 0.7471238213899358, loss = 7.848902627813912\n",
      "80\n",
      "Accuracy = 0.7525399287762967, loss = 7.680794663944046\n",
      "80\n",
      "Accuracy = 0.7576491416855012, loss = 7.522212250805984\n",
      "80\n",
      "Accuracy = 0.762473256022324, loss = 7.372478875747556\n",
      "80\n",
      "Accuracy = 0.7670324784293931, loss = 7.230967354463402\n",
      "80\n",
      "Accuracy = 0.7713455424780697, loss = 7.097096224601904\n",
      "80\n",
      "Accuracy = 0.7754298163623683, loss = 6.970326403105135\n",
      "80\n",
      "Accuracy = 0.7793014027173136, loss = 6.850158087994691\n",
      "80\n",
      "Accuracy = 0.7829752311376785, loss = 6.7361278867268854\n",
      "80\n",
      "Accuracy = 0.7864651439309366, loss = 6.6278061545479\n",
      "80\n",
      "Accuracy = 0.789783975599218, loss = 6.52479452749143\n",
      "80\n",
      "Accuracy = 0.7929436265088741, loss = 6.426723635784323\n",
      "80\n",
      "Accuracy = 0.7959551311727175, loss = 6.333250984466844\n",
      "80\n",
      "Accuracy = 0.7988287215389196, loss = 6.244058988998884\n",
      "80\n",
      "Accuracy = 0.8015738856517313, loss = 6.158853154517919\n",
      "80\n",
      "Accuracy = 0.8041994220224955, loss = 6.077360388243204\n",
      "80\n",
      "Accuracy = 0.8067134900246579, loss = 5.999327435289173\n",
      "80\n",
      "Accuracy = 0.8091236566035457, loss = 5.924519428862943\n",
      "80\n",
      "Accuracy = 0.8114369395704228, loss = 5.85271854648091\n",
      "80\n",
      "Accuracy = 0.8136598477306107, loss = 5.783722764451193\n",
      "80\n",
      "Accuracy = 0.8157984180772074, loss = 5.717344703435605\n",
      "80\n",
      "Accuracy = 0.817858250264998, loss = 5.6534105584304495\n",
      "80\n",
      "Accuracy = 0.8198445385634594, loss = 5.591759106992514\n",
      "80\n",
      "Accuracy = 0.8217621014732136, loss = 5.5322407899881405\n",
      "80\n",
      "Accuracy = 0.8236154091768056, loss = 5.474716859561692\n",
      "80\n",
      "Accuracy = 0.8254086089821822, loss = 5.419058589407594\n",
      "80\n",
      "Accuracy = 0.8271455489056652, loss = 5.3651465427897005\n",
      "80\n",
      "Accuracy = 0.828829799530483, loss = 5.312869894084825\n",
      "80\n",
      "Accuracy = 0.8304646742669655, loss = 5.262125799936237\n",
      "80\n",
      "Accuracy = 0.8320532481312917, loss = 5.21281881638911\n",
      "80\n",
      "Accuracy = 0.8335983751511302, loss = 5.164860358645181\n",
      "80\n",
      "Accuracy = 0.8351027044985844, loss = 5.1181682003199915\n",
      "80\n",
      "Accuracy = 0.8365686954435183, loss = 5.072666009313748\n",
      "80\n",
      "Accuracy = 0.8379986312135294, loss = 5.028282917618301\n",
      "80\n",
      "Accuracy = 0.8393946318405204, loss = 4.984953122578509\n",
      "80\n",
      "Accuracy = 0.8407586660679871, loss = 4.942615517307669\n",
      "80\n",
      "Accuracy = 0.8420925623877059, loss = 4.901213348125034\n",
      "80\n",
      "Accuracy = 0.8433980192694912, loss = 4.860693897039281\n",
      "80\n",
      "Accuracy = 0.8446766146430326, loss = 4.821008187446308\n",
      "80\n",
      "Accuracy = 0.8459298146865055, loss = 4.78211071134375\n",
      "80\n",
      "Accuracy = 0.8471589819726535, loss = 4.743959176488637\n",
      "80\n",
      "Accuracy = 0.8483653830193258, loss = 4.7065142720398665\n",
      "80\n",
      "Accuracy = 0.8495501952880261, loss = 4.669739451333612\n",
      "80\n",
      "Accuracy = 0.8507145136708348, loss = 4.633600730538836\n",
      "80\n",
      "Accuracy = 0.8518593565031225, loss = 4.598066502031561\n",
      "80\n",
      "Accuracy = 0.8529856711367318, loss = 4.563107361411543\n",
      "80\n",
      "Accuracy = 0.8540943391057692, loss = 4.52869594716375\n",
      "80\n",
      "Accuracy = 0.8551861809147984, loss = 4.494806792039885\n",
      "80\n",
      "Accuracy = 0.8562619604770509, loss = 4.461416185302931\n",
      "80\n",
      "Accuracy = 0.8573223892282429, loss = 4.428502045040339\n",
      "80\n",
      "Accuracy = 0.8583681299397239, loss = 4.39604379980953\n",
      "80\n",
      "Accuracy = 0.859399800252943, loss = 4.364022278933302\n",
      "80\n",
      "Accuracy = 0.8604179759556119, loss = 4.3324196108125665\n",
      "80\n",
      "Accuracy = 0.8614231940184528, loss = 4.301219128670179\n",
      "80\n",
      "Accuracy = 0.8624159554100405, loss = 4.270405283182423\n",
      "80\n",
      "Accuracy = 0.8633967277059639, loss = 4.239963561494471\n",
      "80\n",
      "Accuracy = 0.8643659475073477, loss = 4.209880412153063\n",
      "80\n",
      "Accuracy = 0.8653240226826767, loss = 4.180143175523596\n",
      "80\n",
      "Accuracy = 0.8662713344458397, loss = 4.1507400192907\n",
      "80\n",
      "Accuracy = 0.867208239282374, loss = 4.121659878670476\n",
      "80\n",
      "Accuracy = 0.8681350707350066, loss = 4.092892400989923\n",
      "80\n",
      "Accuracy = 0.869052141058783, loss = 4.064427894314195\n",
      "80\n",
      "Accuracy = 0.869959742755319, loss = 4.036257279825694\n",
      "80\n",
      "Accuracy = 0.8708581499950139, loss = 4.00837204768067\n",
      "80\n",
      "Accuracy = 0.8717476199354179, loss = 3.9807642160890517\n",
      "80\n",
      "Accuracy = 0.8726283939433469, loss = 3.953426293381811\n",
      "80\n",
      "Accuracy = 0.873500698727782, loss = 3.926351242847434\n",
      "80\n",
      "Accuracy = 0.8743647473900782, loss = 3.8995324501350006\n",
      "80\n",
      "Accuracy = 0.8752207403975272, loss = 3.8729636930362297\n",
      "80\n",
      "Accuracy = 0.8760688664858782, loss = 3.846639113472566\n",
      "80\n",
      "Accuracy = 0.8769093034960137, loss = 3.820553191526014\n",
      "80\n",
      "Accuracy = 0.87774221914959, loss = 3.7947007213643857\n",
      "80\n",
      "Accuracy = 0.8785677717681095, loss = 3.7690767889223835\n",
      "80\n",
      "Accuracy = 0.8793861109395563, loss = 3.7436767512101867\n",
      "80\n",
      "Accuracy = 0.8801973781364328, loss = 3.7184962171305322\n",
      "80\n",
      "Accuracy = 0.8810017072887477, loss = 3.69353102969401\n",
      "80\n",
      "Accuracy = 0.881799225315249, loss = 3.668777249530372\n",
      "80\n",
      "Accuracy = 0.8825900526159556, loss = 3.644231139601078\n",
      "80\n",
      "Accuracy = 0.8833743035288157, loss = 3.619889151025295\n",
      "80\n",
      "Accuracy = 0.8841520867531163, loss = 3.5957479099379106\n",
      "80\n",
      "Accuracy = 0.8849235057420698, loss = 3.5718042053041907\n",
      "80\n",
      "Accuracy = 0.8856886590668374, loss = 3.548054977621068\n",
      "80\n",
      "Accuracy = 0.8864476407540702, loss = 3.52449730844033\n",
      "80\n",
      "Accuracy = 0.8872005405989097, loss = 3.501128410653584\n",
      "80\n",
      "Accuracy = 0.8879474444552367, loss = 3.477945619483333\n",
      "80\n",
      "Accuracy = 0.8886884345048339, loss = 3.4549463841285615\n",
      "80\n",
      "Accuracy = 0.8894235895070037, loss = 3.4321282600170044\n",
      "80\n",
      "Accuracy = 0.8901529850300669, loss = 3.409488901619729\n",
      "80\n",
      "Accuracy = 0.8908766936660695, loss = 3.3870260557869827\n",
      "80\n",
      "Accuracy = 0.8915947852299217, loss = 3.364737555567186\n",
      "80\n",
      "Accuracy = 0.8923073269441103, loss = 3.342621314473772\n",
      "80\n",
      "Accuracy = 0.8930143836100332, loss = 3.3206753211671733\n",
      "80\n",
      "Accuracy = 0.8937160177669392, loss = 3.298897634521585\n",
      "80\n",
      "Accuracy = 0.8944122898393749, loss = 3.2772863790484386\n",
      "80\n",
      "Accuracy = 0.8951032582739794, loss = 3.2558397406504986\n",
      "80\n",
      "Accuracy = 0.8957889796664035, loss = 3.2345559626824496\n",
      "80\n",
      "Accuracy = 0.8964695088790778, loss = 3.2134333422955748\n",
      "80\n",
      "Accuracy = 0.8971448991504951, loss = 3.1924702270457934\n",
      "80\n",
      "Accuracy = 0.897815202196627, loss = 3.171665011745819\n",
      "80\n",
      "Accuracy = 0.8984804683050513, loss = 3.151016135543611\n",
      "80\n",
      "Accuracy = 0.8991407464223192, loss = 3.130522079210597\n",
      "80\n",
      "Accuracy = 0.8997960842350582, loss = 3.110181362624382\n",
      "80\n",
      "Accuracy = 0.9004465282452668, loss = 3.0899925424316943\n",
      "80\n",
      "Accuracy = 0.9010921238402255, loss = 3.0699542098784707\n",
      "80\n",
      "Accuracy = 0.9017329153574162, loss = 3.050064988794845\n",
      "80\n",
      "Accuracy = 0.9023689461448139, loss = 3.0303235337237675\n",
      "80\n",
      "Accuracy = 0.9030002586168903, loss = 3.0107285281827614\n",
      "80\n",
      "Accuracy = 0.9036268943066396, loss = 2.991278683049112\n",
      "80\n",
      "Accuracy = 0.9042488939139173, loss = 2.971972735059485\n",
      "80\n",
      "Accuracy = 0.9048662973503623, loss = 2.9528094454156344\n",
      "80\n",
      "Accuracy = 0.9054791437811485, loss = 2.9337875984884847\n",
      "80\n",
      "Accuracy = 0.906087471663799, loss = 2.914906000613379\n",
      "80\n",
      "Accuracy = 0.9066913187842773, loss = 2.8961634789698962\n",
      "80\n",
      "Accuracy = 0.9072907222905514, loss = 2.8775588805400467\n",
      "80\n",
      "Accuracy = 0.9078857187238166, loss = 2.8590910711391593\n",
      "80\n",
      "Accuracy = 0.908476344047548, loss = 2.840758934514157\n",
      "80\n",
      "Accuracy = 0.9090626336745378, loss = 2.8225613715043307\n",
      "80\n",
      "Accuracy = 0.909644622492068, loss = 2.8044972992600448\n",
      "80\n",
      "Accuracy = 0.9102223448853498, loss = 2.786565650515192\n",
      "80\n",
      "Accuracy = 0.9107958347593589, loss = 2.768765372909464\n",
      "80\n",
      "Accuracy = 0.9113651255591818, loss = 2.751095428356834\n",
      "80\n",
      "Accuracy = 0.9119302502889814, loss = 2.7335547924568986\n",
      "80\n",
      "Accuracy = 0.9124912415296818, loss = 2.7161424539459498\n",
      "80\n",
      "Accuracy = 0.9130481314554658, loss = 2.69885741418493\n",
      "80\n",
      "Accuracy = 0.9136009518491717, loss = 2.6816986866815467\n",
      "80\n",
      "Accuracy = 0.9141497341166662, loss = 2.6646652966441327\n",
      "80\n",
      "Accuracy = 0.9146945093002724, loss = 2.6477562805648933\n",
      "80\n",
      "Accuracy = 0.9152353080913156, loss = 2.630970685830473\n",
      "80\n",
      "Accuracy = 0.9157721608418562, loss = 2.6143075703578016\n",
      "80\n",
      "Accuracy = 0.916305097575664, loss = 2.597766002253466\n",
      "80\n",
      "Accuracy = 0.9168341479984911, loss = 2.5813450594948493\n",
      "80\n",
      "Accuracy = 0.917359341507693, loss = 2.565043829631508\n",
      "80\n",
      "Accuracy = 0.9178807072012458, loss = 2.548861409505297\n",
      "80\n",
      "Accuracy = 0.9183982738862012, loss = 2.5327969049879324\n",
      "80\n",
      "Accuracy = 0.9189120700866218, loss = 2.516849430734695\n",
      "80\n",
      "Accuracy = 0.9194221240510315, loss = 2.501018109953166\n",
      "80\n",
      "Accuracy = 0.9199284637594201, loss = 2.485302074185854\n",
      "80\n",
      "Accuracy = 0.9204311169298269, loss = 2.469700463105794\n",
      "80\n",
      "Accuracy = 0.9209301110245421, loss = 2.4542124243241217\n",
      "80\n",
      "Accuracy = 0.9214254732559451, loss = 2.4388371132088196\n",
      "80\n",
      "Accuracy = 0.9219172305920114, loss = 2.423573692713807\n",
      "80\n",
      "Accuracy = 0.922405409761509, loss = 2.408421333217654\n",
      "80\n",
      "Accuracy = 0.9228900372589063, loss = 2.3933792123712356\n",
      "80\n",
      "Accuracy = 0.9233711393490135, loss = 2.378446514953691\n",
      "80\n",
      "Accuracy = 0.9238487420713742, loss = 2.3636224327360895\n",
      "80\n",
      "Accuracy = 0.9243228712444268, loss = 2.3489061643522904\n",
      "80\n",
      "Accuracy = 0.9247935524694503, loss = 2.334296915176446\n",
      "80\n",
      "Accuracy = 0.9252608111343107, loss = 2.319793897206742\n",
      "80\n",
      "Accuracy = 0.9257246724170218, loss = 2.305396328954866\n",
      "80\n",
      "Accuracy = 0.926185161289132, loss = 2.2911034353408803\n",
      "80\n",
      "Accuracy = 0.926642302518952, loss = 2.2769144475930525\n",
      "80\n",
      "Accuracy = 0.9270961206746307, loss = 2.262828603152368\n",
      "80\n",
      "Accuracy = 0.9275466401270933, loss = 2.248845145581345\n",
      "80\n",
      "Accuracy = 0.9279938850528493, loss = 2.2349633244768947\n",
      "80\n",
      "Accuracy = 0.928437879436678, loss = 2.221182395386926\n",
      "80\n",
      "Accuracy = 0.9288786470742032, loss = 2.207501619730464\n",
      "80\n",
      "Accuracy = 0.9293162115743625, loss = 2.1939202647210068\n",
      "80\n",
      "Accuracy = 0.929750596361777, loss = 2.18043760329295\n",
      "80\n",
      "Accuracy = 0.9301818246790317, loss = 2.1670529140308346\n",
      "80\n",
      "Accuracy = 0.9306099195888682, loss = 2.153765481101253\n",
      "80\n",
      "Accuracy = 0.9310349039763007, loss = 2.140574594187215\n",
      "80\n",
      "Accuracy = 0.9314568005506547, loss = 2.1274795484248434\n",
      "80\n",
      "Accuracy = 0.9318756318475372, loss = 2.1144796443422167\n",
      "80\n",
      "Accuracy = 0.9322914202307424, loss = 2.101574187800238\n",
      "80\n",
      "Accuracy = 0.9327041878940956, loss = 2.088762489935392\n",
      "80\n",
      "Accuracy = 0.9331139568632403, loss = 2.07604386710427\n",
      "80\n",
      "Accuracy = 0.9335207489973727, loss = 2.0634176408297558\n",
      "80\n",
      "Accuracy = 0.9339245859909244, loss = 2.050883137748766\n",
      "80\n",
      "Accuracy = 0.9343254893752001, loss = 2.0384396895614483\n",
      "80\n",
      "Accuracy = 0.9347234805199698, loss = 2.0260866329817437\n",
      "80\n",
      "Accuracy = 0.9351185806350203, loss = 2.0138233096892355\n",
      "80\n",
      "Accuracy = 0.9355108107716674, loss = 2.001649066282208\n",
      "80\n",
      "Accuracy = 0.935900191824232, loss = 1.9895632542318489\n",
      "80\n",
      "Accuracy = 0.9362867445314806, loss = 1.9775652298375008\n",
      "80\n",
      "Accuracy = 0.9366704894780352, loss = 1.9656543541829499\n",
      "80\n",
      "Accuracy = 0.9370514470957505, loss = 1.9538299930936387\n",
      "80\n",
      "Accuracy = 0.9374296376650633, loss = 1.9420915170947926\n",
      "80\n",
      "Accuracy = 0.937805081316315, loss = 1.9304383013703916\n",
      "80\n",
      "Accuracy = 0.9381777980310466, loss = 1.9188697257229481\n",
      "80\n",
      "Accuracy = 0.9385478076432711, loss = 1.907385174534029\n",
      "80\n",
      "Accuracy = 0.9389151298407215, loss = 1.8959840367255203\n",
      "80\n",
      "Accuracy = 0.9392797841660769, loss = 1.884665705721556\n",
      "80\n",
      "Accuracy = 0.9396417900181685, loss = 1.8734295794111102\n",
      "80\n",
      "Accuracy = 0.9400011666531647, loss = 1.8622750601111888\n",
      "80\n",
      "Accuracy = 0.9403579331857378, loss = 1.8512015545306277\n",
      "80\n",
      "Accuracy = 0.9407121085902129, loss = 1.84020847373444\n",
      "80\n",
      "Accuracy = 0.9410637117016991, loss = 1.8292952331086905\n",
      "80\n",
      "Accuracy = 0.9414127612172044, loss = 1.8184612523259003\n",
      "80\n",
      "Accuracy = 0.9417592756967355, loss = 1.807705955310913\n",
      "80\n",
      "Accuracy = 0.942103273564381, loss = 1.7970287702072532\n",
      "80\n",
      "Accuracy = 0.9424447731093828, loss = 1.7864291293439056\n",
      "80\n",
      "Accuracy = 0.942783792487191, loss = 1.7759064692025501\n",
      "80\n",
      "Accuracy = 0.9431203497205067, loss = 1.765460230385191\n",
      "80\n",
      "Accuracy = 0.9434544627003127, loss = 1.7550898575821854\n",
      "80\n",
      "Accuracy = 0.9437861491868904, loss = 1.744794799540659\n",
      "80\n",
      "Accuracy = 0.944115426810826, loss = 1.7345745090332894\n",
      "80\n",
      "Accuracy = 0.9444423130740048, loss = 1.7244284428274372\n",
      "80\n",
      "Accuracy = 0.9447668253505946, loss = 1.7143560616546292\n",
      "80\n",
      "Accuracy = 0.9450889808880182, loss = 1.7043568301803695\n",
      "80\n",
      "Accuracy = 0.9454087968079155, loss = 1.6944302169742707\n",
      "80\n",
      "Accuracy = 0.945726290107096, loss = 1.6845756944805026\n",
      "80\n",
      "Accuracy = 0.946041477658481, loss = 1.6747927389885369\n",
      "80\n",
      "Accuracy = 0.946354376212037, loss = 1.6650808306041918\n",
      "80\n",
      "Accuracy = 0.9466650023956986, loss = 1.6554394532209564\n",
      "80\n",
      "Accuracy = 0.9469733727162846, loss = 1.6458680944915958\n",
      "80\n",
      "Accuracy = 0.9472795035604027, loss = 1.6363662458000339\n",
      "80\n",
      "Accuracy = 0.9475834111953478, loss = 1.6269334022334896\n",
      "80\n",
      "Accuracy = 0.9478851117699916, loss = 1.617569062554877\n",
      "80\n",
      "Accuracy = 0.9481846213156626, loss = 1.6082727291754577\n",
      "80\n",
      "Accuracy = 0.9484819557470204, loss = 1.599043908127738\n",
      "80\n",
      "Accuracy = 0.9487771308629203, loss = 1.5898821090386097\n",
      "80\n",
      "Accuracy = 0.9490701623472715, loss = 1.5807868451027252\n",
      "80\n",
      "Accuracy = 0.9493610657698874, loss = 1.5717576330561012\n",
      "80\n",
      "Accuracy = 0.9496498565873286, loss = 1.5627939931499586\n",
      "80\n",
      "Accuracy = 0.9499365501437382, loss = 1.5538954491247776\n",
      "80\n",
      "Accuracy = 0.9502211616716719, loss = 1.5450615281845643\n",
      "80\n",
      "Accuracy = 0.9505037062929182, loss = 1.5362917609713567\n",
      "80\n",
      "Accuracy = 0.9507841990193151, loss = 1.527585681539917\n",
      "80\n",
      "Accuracy = 0.9510626547535568, loss = 1.5189428273326415\n",
      "80\n",
      "Accuracy = 0.9513390882899969, loss = 1.5103627391546768\n",
      "80\n",
      "Accuracy = 0.951613514315443, loss = 1.5018449611492364\n",
      "80\n",
      "Accuracy = 0.9518859474099456, loss = 1.4933890407731156\n",
      "80\n",
      "Accuracy = 0.9521564020475806, loss = 1.484994528772399\n",
      "80\n",
      "Accuracy = 0.9524248925972258, loss = 1.4766609791583654\n",
      "80\n",
      "Accuracy = 0.9526914333233315, loss = 1.468387949183581\n",
      "80\n",
      "Accuracy = 0.9529560383866837, loss = 1.4601749993181805\n",
      "80\n",
      "Accuracy = 0.9532187218451634, loss = 1.4520216932263341\n",
      "80\n",
      "Accuracy = 0.953479497654498, loss = 1.4439275977428974\n",
      "80\n",
      "Accuracy = 0.9537383796690083, loss = 1.435892282850241\n",
      "80\n",
      "Accuracy = 0.9539953816423491, loss = 1.4279153216552583\n",
      "80\n",
      "Accuracy = 0.954250517228244, loss = 1.4199962903665582\n",
      "80\n",
      "Accuracy = 0.9545037999812154, loss = 1.412134768271819\n",
      "80\n",
      "Accuracy = 0.9547552433573073, loss = 1.4043303377153227\n",
      "80\n",
      "Accuracy = 0.9550048607148046, loss = 1.396582584075666\n",
      "80\n",
      "Accuracy = 0.9552526653149456, loss = 1.3888910957436251\n",
      "80\n",
      "Accuracy = 0.9554986703226291, loss = 1.3812554641002002\n",
      "80\n",
      "Accuracy = 0.9557428888071176, loss = 1.3736752834948243\n",
      "80\n",
      "Accuracy = 0.9559853337427326, loss = 1.36615015122373\n",
      "80\n",
      "Accuracy = 0.9562260180095479, loss = 1.3586796675084876\n",
      "80\n",
      "Accuracy = 0.9564649543940745, loss = 1.3512634354746904\n",
      "80\n",
      "Accuracy = 0.9567021555899435, loss = 1.3439010611308138\n",
      "80\n",
      "Accuracy = 0.9569376341985807, loss = 1.3365921533472267\n",
      "80\n",
      "Accuracy = 0.9571714027298792, loss = 1.3293363238353542\n",
      "80\n",
      "Accuracy = 0.9574034736028645, loss = 1.3221331871270026\n",
      "80\n",
      "Accuracy = 0.9576338591463567, loss = 1.3149823605538336\n",
      "80\n",
      "Accuracy = 0.9578625715996262, loss = 1.3078834642269945\n",
      "80\n",
      "Accuracy = 0.9580896231130452, loss = 1.3008361210168928\n",
      "80\n",
      "Accuracy = 0.9583150257487351, loss = 1.2938399565331253\n",
      "80\n",
      "Accuracy = 0.9585387914812075, loss = 1.2868945991045582\n",
      "80\n",
      "Accuracy = 0.9587609321980018, loss = 1.2799996797595437\n",
      "80\n",
      "Accuracy = 0.9589814597003179, loss = 1.2731548322062956\n",
      "80\n",
      "Accuracy = 0.9592003857036434, loss = 1.2663596928134\n",
      "80\n",
      "Accuracy = 0.9594177218383774, loss = 1.2596139005904683\n",
      "80\n",
      "Accuracy = 0.9596334796504488, loss = 1.2529170971689425\n",
      "80\n",
      "Accuracy = 0.9598476706019302, loss = 1.2462689267830354\n",
      "80\n",
      "Accuracy = 0.9600603060716482, loss = 1.239669036250803\n",
      "80\n",
      "Accuracy = 0.9602713973557875, loss = 1.2331170749553706\n",
      "80\n",
      "Accuracy = 0.9604809556684925, loss = 1.2266126948262859\n",
      "80\n",
      "Accuracy = 0.9606889921424627, loss = 1.2201555503210126\n",
      "80\n",
      "Accuracy = 0.9608955178295455, loss = 1.2137452984065598\n",
      "80\n",
      "Accuracy = 0.9611005437013228, loss = 1.207381598541242\n",
      "80\n",
      "Accuracy = 0.9613040806496952, loss = 1.2010641126565775\n",
      "80\n",
      "Accuracy = 0.9615061394874602, loss = 1.1947925051393151\n",
      "80\n",
      "Accuracy = 0.9617067309488878, loss = 1.188566442813598\n",
      "80\n",
      "Accuracy = 0.96190586569029, loss = 1.182385594923249\n",
      "80\n",
      "Accuracy = 0.9621035542905886, loss = 1.17624963311419\n",
      "80\n",
      "Accuracy = 0.9622998072518761, loss = 1.1701582314169934\n",
      "80\n",
      "Accuracy = 0.9624946349999749, loss = 1.1641110662295546\n",
      "80\n",
      "Accuracy = 0.9626880478849907, loss = 1.1581078162998932\n",
      "80\n",
      "Accuracy = 0.9628800561818632, loss = 1.1521481627090806\n",
      "80\n",
      "Accuracy = 0.9630706700909115, loss = 1.1462317888542919\n",
      "80\n",
      "Accuracy = 0.9632598997383769, loss = 1.1403583804319775\n",
      "80\n",
      "Accuracy = 0.9634477551769602, loss = 1.1345276254211631\n",
      "80\n",
      "Accuracy = 0.9636342463863568, loss = 1.1287392140668706\n",
      "80\n",
      "Accuracy = 0.9638193832737862, loss = 1.12299283886365\n",
      "80\n",
      "Accuracy = 0.9640031756745191, loss = 1.1172881945392485\n",
      "80\n",
      "Accuracy = 0.9641856333523994, loss = 1.1116249780383847\n",
      "80\n",
      "Accuracy = 0.9643667660003638, loss = 1.1060028885066424\n",
      "80\n",
      "Accuracy = 0.9645465832409561, loss = 1.1004216272744902\n",
      "80\n",
      "Accuracy = 0.964725094626839, loss = 1.094880897841406\n",
      "80\n",
      "Accuracy = 0.9649023096413012, loss = 1.0893804058601284\n",
      "80\n",
      "Accuracy = 0.965078237698762, loss = 1.0839198591210095\n",
      "80\n",
      "Accuracy = 0.9652528881452705, loss = 1.078498967536499\n",
      "80\n",
      "Accuracy = 0.9654262702590035, loss = 1.0731174431257202\n",
      "80\n",
      "Accuracy = 0.9655983932507571, loss = 1.067774999999178\n",
      "80\n",
      "Accuracy = 0.9657692662644369, loss = 1.0624713543435613\n",
      "80\n",
      "Accuracy = 0.9659388983775439, loss = 1.0572062244066713\n",
      "80\n",
      "Accuracy = 0.9661072986016559, loss = 1.0519793304824465\n",
      "80\n",
      "Accuracy = 0.9662744758829077, loss = 1.0467903948961053\n",
      "80\n",
      "Accuracy = 0.9664404391024651, loss = 1.0416391419893873\n",
      "80\n",
      "Accuracy = 0.9666051970769974, loss = 1.0365252981059192\n",
      "80\n",
      "Accuracy = 0.9667687585591458, loss = 1.0314485915766611\n",
      "80\n",
      "Accuracy = 0.9669311322379881, loss = 1.0264087527054864\n",
      "80\n",
      "Accuracy = 0.9670923267395007, loss = 1.0214055137548432\n",
      "80\n",
      "Accuracy = 0.9672523506270169, loss = 1.0164386089315358\n",
      "80\n",
      "Accuracy = 0.967411212401681, loss = 1.0115077743726038\n",
      "80\n",
      "Accuracy = 0.9675689205029016, loss = 1.0066127481312985\n",
      "80\n",
      "Accuracy = 0.9677254833087982, loss = 1.0017532701631713\n",
      "80\n",
      "Accuracy = 0.9678809091366474, loss = 0.996929082312259\n",
      "80\n",
      "Accuracy = 0.9680352062433245, loss = 0.9921399282973618\n",
      "80\n",
      "Accuracy = 0.968188382825742, loss = 0.9873855536984371\n",
      "80\n",
      "Accuracy = 0.9683404470212855, loss = 0.982665705943074\n",
      "80\n",
      "Accuracy = 0.9684914069082453, loss = 0.9779801342930836\n",
      "80\n",
      "Accuracy = 0.9686412705062463, loss = 0.9733285898311725\n",
      "80\n",
      "Accuracy = 0.9687900457766734, loss = 0.9687108254477195\n",
      "80\n",
      "Accuracy = 0.9689377406230951, loss = 0.9641265958276497\n",
      "80\n",
      "Accuracy = 0.9690843628916831, loss = 0.9595756574374009\n",
      "80\n",
      "Accuracy = 0.9692299203716288, loss = 0.9550577685119856\n",
      "80\n",
      "Accuracy = 0.9693744207955577, loss = 0.950572689042145\n",
      "80\n",
      "Accuracy = 0.9695178718399398, loss = 0.9461201807616039\n",
      "80\n",
      "Accuracy = 0.9696602811254974, loss = 0.9417000071344048\n",
      "80\n",
      "Accuracy = 0.9698016562176105, loss = 0.9373119333423509\n",
      "80\n",
      "Accuracy = 0.9699420046267179, loss = 0.9329557262725228\n",
      "80\n",
      "Accuracy = 0.9700813338087166, loss = 0.9286311545049003\n",
      "80\n",
      "Accuracy = 0.9702196511653582, loss = 0.9243379883000656\n",
      "80\n",
      "Accuracy = 0.9703569640446416, loss = 0.9200759995869976\n",
      "80\n",
      "Accuracy = 0.9704932797412035, loss = 0.9158449619509575\n",
      "80\n",
      "Accuracy = 0.9706286054967062, loss = 0.9116446506214608\n",
      "80\n",
      "Accuracy = 0.9707629485002219, loss = 0.9074748424603334\n",
      "80\n",
      "Accuracy = 0.970896315888615, loss = 0.9033353159498617\n",
      "80\n",
      "Accuracy = 0.971028714746921, loss = 0.89922585118102\n",
      "80\n",
      "Accuracy = 0.9711601521087229, loss = 0.8951462298417916\n",
      "80\n",
      "Accuracy = 0.9712906349565251, loss = 0.8910962352055682\n",
      "80\n",
      "Accuracy = 0.971420170222124, loss = 0.887075652119638\n",
      "80\n",
      "Accuracy = 0.9715487647869766, loss = 0.8830842669937568\n",
      "80\n",
      "Accuracy = 0.9716764254825657, loss = 0.8791218677887965\n",
      "80\n",
      "Accuracy = 0.9718031590907631, loss = 0.8751882440054886\n",
      "80\n",
      "Accuracy = 0.9719289723441897, loss = 0.8712831866732325\n",
      "80\n",
      "Accuracy = 0.9720538719265736, loss = 0.8674064883389987\n",
      "80\n",
      "Accuracy = 0.9721778644731042, loss = 0.8635579430563112\n",
      "80\n",
      "Accuracy = 0.972300956570786, loss = 0.8597373463742969\n",
      "80\n",
      "Accuracy = 0.9724231547587875, loss = 0.8559444953268363\n",
      "80\n",
      "Accuracy = 0.972544465528789, loss = 0.8521791884217708\n",
      "80\n",
      "Accuracy = 0.9726648953253274, loss = 0.8484412256302065\n",
      "80\n",
      "Accuracy = 0.9727844505461387, loss = 0.8447304083758803\n",
      "80\n",
      "Accuracy = 0.9729031375424975, loss = 0.8410465395246174\n",
      "80\n",
      "Accuracy = 0.973020962619555, loss = 0.8373894233738524\n",
      "80\n",
      "Accuracy = 0.9731379320366732, loss = 0.8337588656422407\n",
      "80\n",
      "Accuracy = 0.9732540520077583, loss = 0.8301546734593277\n",
      "80\n",
      "Accuracy = 0.9733693287015899, loss = 0.8265766553553128\n",
      "80\n",
      "Accuracy = 0.9734837682421495, loss = 0.8230246212508675\n",
      "80\n",
      "Accuracy = 0.9735973767089455, loss = 0.8194983824470459\n",
      "80\n",
      "Accuracy = 0.973710160137336, loss = 0.8159977516152566\n",
      "80\n",
      "Accuracy = 0.9738221245188495, loss = 0.812522542787311\n",
      "80\n",
      "Accuracy = 0.9739332758015036, loss = 0.809072571345542\n",
      "80\n",
      "Accuracy = 0.9740436198901203, loss = 0.8056476540130031\n",
      "80\n",
      "Accuracy = 0.9741531626466404, loss = 0.8022476088437239\n",
      "80\n",
      "Accuracy = 0.9742619098904345, loss = 0.7988722552130485\n",
      "80\n",
      "Accuracy = 0.9743698673986121, loss = 0.7955214138080401\n",
      "80\n",
      "Accuracy = 0.9744770409063286, loss = 0.7921949066179541\n",
      "80\n",
      "Accuracy = 0.9745834361070901, loss = 0.7888925569247797\n",
      "80\n",
      "Accuracy = 0.9746890586530558, loss = 0.7856141892938567\n",
      "80\n",
      "Accuracy = 0.9747939141553382, loss = 0.7823596295645511\n",
      "80\n",
      "Accuracy = 0.9748980081843012, loss = 0.7791287048410046\n",
      "80\n",
      "Accuracy = 0.9750013462698559, loss = 0.7759212434829502\n",
      "80\n",
      "Accuracy = 0.975103933901755, loss = 0.7727370750965925\n",
      "80\n",
      "Accuracy = 0.9752057765298832, loss = 0.7695760305255581\n",
      "80\n",
      "Accuracy = 0.9753068795645481, loss = 0.7664379418419055\n",
      "80\n",
      "Accuracy = 0.9754072483767668, loss = 0.7633226423372078\n",
      "80\n",
      "Accuracy = 0.9755068882985514, loss = 0.7602299665136947\n",
      "80\n",
      "Accuracy = 0.9756058046231921, loss = 0.7571597500754603\n",
      "80\n",
      "Accuracy = 0.9757040026055389, loss = 0.7541118299197365\n",
      "80\n",
      "Accuracy = 0.9758014874622803, loss = 0.7510860441282265\n",
      "80\n",
      "Accuracy = 0.9758982643722206, loss = 0.7480822319585031\n",
      "80\n",
      "Accuracy = 0.9759943384765549, loss = 0.745100233835472\n",
      "80\n",
      "Accuracy = 0.9760897148791425, loss = 0.7421398913428906\n",
      "80\n",
      "Accuracy = 0.9761843986467776, loss = 0.7392010472149556\n",
      "80\n",
      "Accuracy = 0.9762783948094591, loss = 0.7362835453279449\n",
      "80\n",
      "Accuracy = 0.976371708360657, loss = 0.7333872306919293\n",
      "80\n",
      "Accuracy = 0.9764643442575784, loss = 0.7305119494425318\n",
      "80\n",
      "Accuracy = 0.9765563074214306, loss = 0.72765754883276\n",
      "80\n",
      "Accuracy = 0.9766476027376824, loss = 0.7248238772248855\n",
      "80\n",
      "Accuracy = 0.9767382350563235, loss = 0.7220107840823948\n",
      "80\n",
      "Accuracy = 0.9768282091921228, loss = 0.7192181199619859\n",
      "80\n",
      "Accuracy = 0.9769175299248836, loss = 0.7164457365056341\n",
      "80\n",
      "Accuracy = 0.9770062019996975, loss = 0.7136934864327074\n",
      "80\n",
      "Accuracy = 0.977094230127197, loss = 0.710961223532143\n",
      "80\n",
      "Accuracy = 0.9771816189838053, loss = 0.7082488026546829\n",
      "80\n",
      "Accuracy = 0.9772683732119847, loss = 0.7055560797051591\n",
      "80\n",
      "Accuracy = 0.9773544974204835, loss = 0.7028829116348401\n",
      "80\n",
      "Accuracy = 0.9774399961845808, loss = 0.7002291564338313\n",
      "80\n",
      "Accuracy = 0.9775248740463293, loss = 0.6975946731235307\n",
      "80\n",
      "Accuracy = 0.9776091355147967, loss = 0.6949793217491428\n",
      "80\n",
      "Accuracy = 0.9776927850663056, loss = 0.6923829633722375\n",
      "80\n",
      "Accuracy = 0.9777758271446709, loss = 0.6898054600633732\n",
      "80\n",
      "Accuracy = 0.9778582661614359, loss = 0.687246674894769\n",
      "80\n",
      "Accuracy = 0.9779401064961066, loss = 0.6847064719330312\n",
      "80\n",
      "Accuracy = 0.9780213524963848, loss = 0.6821847162319281\n",
      "80\n",
      "Accuracy = 0.9781020084783987, loss = 0.6796812738252258\n",
      "80\n",
      "Accuracy = 0.978182078726932, loss = 0.6771960117195694\n",
      "80\n",
      "Accuracy = 0.978261567495652, loss = 0.6747287978874172\n",
      "80\n",
      "Accuracy = 0.9783404790073355, loss = 0.6722795012600279\n",
      "80\n",
      "Accuracy = 0.9784188174540925, loss = 0.6698479917204958\n",
      "80\n",
      "Accuracy = 0.97849658699759, loss = 0.6674341400968424\n",
      "80\n",
      "Accuracy = 0.9785737917692721, loss = 0.6650378181551492\n",
      "80\n",
      "Accuracy = 0.9786504358705796, loss = 0.6626588985927497\n",
      "80\n",
      "Accuracy = 0.978726523373169, loss = 0.6602972550314642\n",
      "80\n",
      "Accuracy = 0.978802058319127, loss = 0.6579527620108861\n",
      "80\n",
      "Accuracy = 0.9788770447211868, loss = 0.6556252949817178\n",
      "80\n",
      "Accuracy = 0.9789514865629402, loss = 0.6533147302991545\n",
      "80\n",
      "Accuracy = 0.9790253877990501, loss = 0.6510209452163134\n",
      "80\n",
      "Accuracy = 0.97909875235546, loss = 0.6487438178777152\n",
      "80\n",
      "Accuracy = 0.9791715841296024, loss = 0.64648322731281\n",
      "80\n",
      "Accuracy = 0.9792438869906067, loss = 0.6442390534295505\n",
      "80\n",
      "Accuracy = 0.9793156647795039, loss = 0.6420111770080121\n",
      "80\n",
      "Accuracy = 0.9793869213094311, loss = 0.63979947969406\n",
      "80\n",
      "Accuracy = 0.9794576603658338, loss = 0.6376038439930607\n",
      "80\n",
      "Accuracy = 0.9795278857066673, loss = 0.6354241532636427\n",
      "80\n",
      "Accuracy = 0.9795976010625961, loss = 0.6332602917114969\n",
      "80\n",
      "Accuracy = 0.979666810137192, loss = 0.6311121443832247\n",
      "80\n",
      "Accuracy = 0.9797355166071313, loss = 0.6289795971602365\n",
      "80\n",
      "Accuracy = 0.9798037241223898, loss = 0.6268625367526839\n",
      "80\n",
      "Accuracy = 0.9798714363064365, loss = 0.6247608506934424\n",
      "80\n",
      "Accuracy = 0.9799386567564264, loss = 0.6226744273321386\n",
      "80\n",
      "Accuracy = 0.9800053890433919, loss = 0.6206031558292179\n",
      "80\n",
      "Accuracy = 0.9800716367124315, loss = 0.618546926150054\n",
      "80\n",
      "Accuracy = 0.9801374032828991, loss = 0.6165056290591071\n",
      "80\n",
      "Accuracy = 0.9802026922485909, loss = 0.6144791561141183\n",
      "80\n",
      "Accuracy = 0.9802675070779303, loss = 0.6124673996603495\n",
      "80\n",
      "Accuracy = 0.9803318512141528, loss = 0.6104702528248641\n",
      "80\n",
      "Accuracy = 0.9803957280754885, loss = 0.6084876095108508\n",
      "80\n",
      "Accuracy = 0.9804591410553442, loss = 0.6065193643919855\n",
      "80\n",
      "Accuracy = 0.9805220935224831, loss = 0.6045654129068356\n",
      "80\n",
      "Accuracy = 0.9805845888212043, loss = 0.6026256512533077\n",
      "80\n",
      "Accuracy = 0.9806466302715199, loss = 0.6006999763831309\n",
      "80\n",
      "Accuracy = 0.9807082211693319, loss = 0.5987882859963838\n",
      "80\n",
      "Accuracy = 0.980769364786607, loss = 0.5968904785360583\n",
      "80\n",
      "Accuracy = 0.9808300643715505, loss = 0.595006453182667\n",
      "80\n",
      "Accuracy = 0.9808903231487787, loss = 0.593136109848886\n",
      "80\n",
      "Accuracy = 0.9809501443194906, loss = 0.5912793491742352\n",
      "80\n",
      "Accuracy = 0.9810095310616374, loss = 0.5894360725198051\n",
      "80\n",
      "Accuracy = 0.9810684865300918, loss = 0.5876061819630122\n",
      "80\n",
      "Accuracy = 0.9811270138568157, loss = 0.5857895802923997\n",
      "80\n",
      "Accuracy = 0.9811851161510257, loss = 0.5839861710024704\n",
      "80\n",
      "Accuracy = 0.9812427964993594, loss = 0.5821958582885636\n",
      "80\n",
      "Accuracy = 0.9813000579660387, loss = 0.5804185470417631\n",
      "80\n",
      "Accuracy = 0.9813569035930327, loss = 0.5786541428438442\n",
      "80\n",
      "Accuracy = 0.9814133364002195, loss = 0.5769025519622594\n",
      "80\n",
      "Accuracy = 0.9814693593855464, loss = 0.575163681345159\n",
      "80\n",
      "Accuracy = 0.981524975525189, loss = 0.5734374386164451\n",
      "80\n",
      "Accuracy = 0.9815801877737101, loss = 0.571723732070869\n",
      "80\n",
      "Accuracy = 0.9816349990642156, loss = 0.5700224706691545\n",
      "80\n",
      "Accuracy = 0.981689412308511, loss = 0.5683335640331632\n",
      "80\n",
      "Accuracy = 0.9817434303972562, loss = 0.5666569224410954\n",
      "80\n",
      "Accuracy = 0.9817970562001181, loss = 0.5649924568227216\n",
      "80\n",
      "Accuracy = 0.9818502925659246, loss = 0.5633400787546494\n",
      "80\n",
      "Accuracy = 0.9819031423228143, loss = 0.5616997004556299\n",
      "80\n",
      "Accuracy = 0.9819556082783879, loss = 0.560071234781891\n",
      "80\n",
      "Accuracy = 0.982007693219857, loss = 0.5584545952225096\n",
      "80\n",
      "Accuracy = 0.982059399914192, loss = 0.5568496958948155\n",
      "80\n",
      "Accuracy = 0.9821107311082692, loss = 0.5552564515398277\n",
      "80\n",
      "Accuracy = 0.9821616895290168, loss = 0.5536747775177275\n",
      "80\n",
      "Accuracy = 0.9822122778835598, loss = 0.5521045898033606\n",
      "80\n",
      "Accuracy = 0.9822624988593637, loss = 0.5505458049817732\n",
      "80\n",
      "Accuracy = 0.9823123551243772, loss = 0.5489983402437812\n",
      "80\n",
      "Accuracy = 0.9823618493271741, loss = 0.5474621133815704\n",
      "80\n",
      "Accuracy = 0.9824109840970939, loss = 0.5459370427843299\n",
      "80\n",
      "Accuracy = 0.9824597620443816, loss = 0.5444230474339167\n",
      "80\n",
      "Accuracy = 0.9825081857603263, loss = 0.5429200469005495\n",
      "80\n",
      "Accuracy = 0.9825562578173986, loss = 0.5414279613385421\n",
      "80\n",
      "Accuracy = 0.9826039807693879, loss = 0.5399467114820518\n",
      "80\n",
      "Accuracy = 0.9826513571515374, loss = 0.5384762186408787\n",
      "80\n",
      "Accuracy = 0.9826983894806791, loss = 0.5370164046962775\n",
      "80\n",
      "Accuracy = 0.9827450802553676, loss = 0.5355671920968124\n",
      "80\n",
      "Accuracy = 0.9827914319560123, loss = 0.5341285038542345\n",
      "80\n",
      "Accuracy = 0.9828374470450101, loss = 0.5327002635393943\n",
      "80\n",
      "Accuracy = 0.9828831279668753, loss = 0.531282395278178\n",
      "80\n",
      "Accuracy = 0.98292847714837, loss = 0.5298748237474796\n",
      "80\n",
      "Accuracy = 0.9829734969986329, loss = 0.5284774741711994\n",
      "80\n",
      "Accuracy = 0.9830181899093071, loss = 0.5270902723162699\n",
      "80\n",
      "Accuracy = 0.9830625582546674, loss = 0.5257131444887138\n",
      "80\n",
      "Accuracy = 0.9831066043917462, loss = 0.5243460175297268\n",
      "80\n",
      "Accuracy = 0.9831503306604591, loss = 0.5229888188117949\n",
      "80\n",
      "Accuracy = 0.9831937393837288, loss = 0.5216414762348317\n",
      "80\n",
      "Accuracy = 0.9832368328676084, loss = 0.5203039182223523\n",
      "80\n",
      "Accuracy = 0.9832796134014048, loss = 0.5189760737176674\n",
      "80\n",
      "Accuracy = 0.9833220832577989, loss = 0.5176578721801105\n",
      "80\n",
      "Accuracy = 0.9833642446929678, loss = 0.5163492435812906\n",
      "80\n",
      "Accuracy = 0.9834060999467036, loss = 0.51505011840137\n",
      "80\n",
      "Accuracy = 0.9834476512425327, loss = 0.5137604276253736\n",
      "80\n",
      "Accuracy = 0.9834889007878344, loss = 0.5124801027395198\n",
      "80\n",
      "Accuracy = 0.9835298507739572, loss = 0.5112090757275848\n",
      "80\n",
      "Accuracy = 0.9835705033763362, loss = 0.509947279067284\n",
      "80\n",
      "Accuracy = 0.9836108607546079, loss = 0.5086946457266917\n",
      "80\n",
      "Accuracy = 0.9836509250527256, loss = 0.5074511091606717\n",
      "80\n",
      "Accuracy = 0.9836906983990725, loss = 0.5062166033073494\n",
      "80\n",
      "Accuracy = 0.9837301829065758, loss = 0.5049910625845981\n",
      "80\n",
      "Accuracy = 0.9837693806728178, loss = 0.5037744218865582\n",
      "80\n",
      "Accuracy = 0.9838082937801484, loss = 0.5025666165801742\n",
      "80\n",
      "Accuracy = 0.9838469242957949, loss = 0.501367582501766\n",
      "80\n",
      "Accuracy = 0.9838852742719721, loss = 0.5001772559536168\n",
      "80\n",
      "Accuracy = 0.9839233457459916, loss = 0.4989955737005903\n",
      "80\n",
      "Accuracy = 0.9839611407403698, loss = 0.49782247296677157\n",
      "80\n",
      "Accuracy = 0.983998661262935, loss = 0.49665789143213185\n",
      "80\n",
      "Accuracy = 0.984035909306935, loss = 0.4955017672292178\n",
      "80\n",
      "Accuracy = 0.9840728868511416, loss = 0.4943540389398664\n",
      "80\n",
      "Accuracy = 0.9841095958599573, loss = 0.49321464559193845\n",
      "80\n",
      "Accuracy = 0.9841460382835184, loss = 0.49208352665608235\n",
      "80\n",
      "Accuracy = 0.9841822160577992, loss = 0.4909606220425201\n",
      "80\n",
      "Accuracy = 0.9842181311047148, loss = 0.4898458720978498\n",
      "80\n",
      "Accuracy = 0.9842537853322231, loss = 0.4887392176018827\n",
      "80\n",
      "Accuracy = 0.9842891806344258, loss = 0.4876405997644916\n",
      "80\n",
      "Accuracy = 0.9843243188916703, loss = 0.48654996022249214\n",
      "80\n",
      "Accuracy = 0.9843592019706475, loss = 0.4854672410365393\n",
      "80\n",
      "Accuracy = 0.9843938317244932, loss = 0.48439238468805235\n",
      "80\n",
      "Accuracy = 0.984428209992885, loss = 0.4833253340761547\n",
      "80\n",
      "Accuracy = 0.9844623386021407, loss = 0.48226603251464545\n",
      "80\n",
      "Accuracy = 0.984496219365315, loss = 0.481214423728985\n",
      "80\n",
      "Accuracy = 0.984529854082296, loss = 0.4801704518533059\n",
      "80\n",
      "Accuracy = 0.984563244539901, loss = 0.47913406142744613\n",
      "80\n",
      "Accuracy = 0.984596392511971, loss = 0.47810519739400126\n",
      "80\n",
      "Accuracy = 0.9846292997594651, loss = 0.47708380509540166\n",
      "80\n",
      "Accuracy = 0.9846619680305546, loss = 0.47606983027100525\n",
      "80\n",
      "Accuracy = 0.9846943990607148, loss = 0.4750632190542195\n",
      "80\n",
      "Accuracy = 0.984726594572818, loss = 0.474063917969637\n",
      "80\n",
      "Accuracy = 0.9847585562772246, loss = 0.4730718739301949\n",
      "80\n",
      "Accuracy = 0.9847902858718746, loss = 0.4720870342343552\n",
      "80\n",
      "Accuracy = 0.9848217850423768, loss = 0.4711093465633038\n",
      "80\n",
      "Accuracy = 0.9848530554620996, loss = 0.4701387589781739\n",
      "80\n",
      "Accuracy = 0.9848840987922582, loss = 0.46917521991728484\n",
      "80\n",
      "Accuracy = 0.984914916682005, loss = 0.46821867819340124\n",
      "80\n",
      "Accuracy = 0.9849455107685152, loss = 0.46726908299101744\n",
      "80\n",
      "Accuracy = 0.9849758826770749, loss = 0.46632638386365544\n",
      "80\n",
      "Accuracy = 0.9850060340211674, loss = 0.46539053073118597\n",
      "80\n",
      "Accuracy = 0.9850359664025583, loss = 0.4644614738771673\n",
      "80\n",
      "Accuracy = 0.9850656814113812, loss = 0.46353916394620437\n",
      "80\n",
      "Accuracy = 0.985095180626222, loss = 0.462623551941328\n",
      "80\n",
      "Accuracy = 0.9851244656142027, loss = 0.461714589221389\n",
      "80\n",
      "Accuracy = 0.9851535379310645, loss = 0.4608122274984788\n",
      "80\n",
      "Accuracy = 0.9851823991212509, loss = 0.45991641883535905\n",
      "80\n",
      "Accuracy = 0.9852110507179892, loss = 0.45902711564291804\n",
      "80\n",
      "Accuracy = 0.9852394942433723, loss = 0.458144270677643\n",
      "80\n",
      "Accuracy = 0.9852677312084397, loss = 0.45726783703910706\n",
      "80\n",
      "Accuracy = 0.9852957631132571, loss = 0.45639776816748306\n",
      "80\n",
      "Accuracy = 0.9853235914469969, loss = 0.4555340178410635\n",
      "80\n",
      "Accuracy = 0.9853512176880168, loss = 0.45467654017381154\n",
      "80\n",
      "Accuracy = 0.9853786433039387, loss = 0.4538252896129181\n",
      "80\n",
      "Accuracy = 0.9854058697517261, loss = 0.4529802209363848\n",
      "80\n",
      "Accuracy = 0.9854328984777622, loss = 0.45214128925062147\n",
      "80\n",
      "Accuracy = 0.985459730917926, loss = 0.45130844998805986\n",
      "80\n",
      "Accuracy = 0.9854863684976695, loss = 0.450481658904787\n",
      "80\n",
      "Accuracy = 0.9855128126320923, loss = 0.44966087207819444\n",
      "80\n",
      "Accuracy = 0.985539064726018, loss = 0.4488460459046452\n",
      "80\n",
      "Accuracy = 0.9855651261740677, loss = 0.44803713709715753\n",
      "80\n",
      "Accuracy = 0.9855909983607347, loss = 0.44723410268310426\n",
      "80\n",
      "Accuracy = 0.9856166826604581, loss = 0.44643690000193115\n",
      "80\n",
      "Accuracy = 0.9856421804376956, loss = 0.4456454867028893\n",
      "80\n",
      "Accuracy = 0.985667493046996, loss = 0.44485982074278735\n",
      "80\n",
      "Accuracy = 0.9856926218330712, loss = 0.44407986038375524\n",
      "80\n",
      "Accuracy = 0.9857175681308676, loss = 0.44330556419102934\n",
      "80\n",
      "Accuracy = 0.9857423332656373, loss = 0.44253689103075056\n",
      "80\n",
      "Accuracy = 0.9857669185530079, loss = 0.4417738000677772\n",
      "80\n",
      "Accuracy = 0.9857913252990529, loss = 0.44101625076351947\n",
      "80\n",
      "Accuracy = 0.9858155548003611, loss = 0.44026420287378165\n",
      "80\n",
      "Accuracy = 0.9858396083441051, loss = 0.43951761644662807\n",
      "80\n",
      "Accuracy = 0.9858634872081101, loss = 0.4387764518202576\n",
      "80\n",
      "Accuracy = 0.9858871926609213, loss = 0.43804066962089844\n",
      "80\n",
      "Accuracy = 0.9859107259618718, loss = 0.43731023076071507\n",
      "80\n",
      "Accuracy = 0.9859340883611492, loss = 0.43658509643573423\n",
      "80\n",
      "Accuracy = 0.985957281099862, loss = 0.4358652281237799\n",
      "80\n",
      "Accuracy = 0.9859803054101058, loss = 0.43515058758242997\n",
      "80\n",
      "Accuracy = 0.9860031625150285, loss = 0.43444113684698316\n",
      "80\n",
      "Accuracy = 0.9860258536288953, loss = 0.4337368382284422\n",
      "80\n",
      "Accuracy = 0.9860483799571532, loss = 0.4330376543115122\n",
      "80\n",
      "Accuracy = 0.9860707426964954, loss = 0.432343547952612\n",
      "80\n",
      "Accuracy = 0.9860929430349241, loss = 0.4316544822779028\n",
      "80\n",
      "Accuracy = 0.9861149821518146, loss = 0.43097042068132685\n",
      "80\n",
      "Accuracy = 0.986136861217977, loss = 0.43029132682266436\n",
      "80\n",
      "Accuracy = 0.986158581395719, loss = 0.4296171646256034\n",
      "80\n",
      "Accuracy = 0.9861801438389076, loss = 0.4289478982758211\n",
      "80\n",
      "Accuracy = 0.9862015496930302, loss = 0.42828349221908396\n",
      "80\n",
      "Accuracy = 0.9862228000952553, loss = 0.42762391115935694\n",
      "80\n",
      "Accuracy = 0.9862438961744936, loss = 0.42696912005692866\n",
      "80\n",
      "Accuracy = 0.9862648390514571, loss = 0.42631908412655156\n",
      "80\n",
      "Accuracy = 0.9862856298387194, loss = 0.4256737688355915\n",
      "80\n",
      "Accuracy = 0.9863062696407741, loss = 0.4250331399021953\n",
      "80\n",
      "Accuracy = 0.9863267595540939, loss = 0.42439716329346844\n",
      "80\n",
      "Accuracy = 0.9863471006671892, loss = 0.4237658052236669\n",
      "80\n",
      "Accuracy = 0.9863672940606649, loss = 0.4231390321524044\n",
      "80\n",
      "Accuracy = 0.986387340807279, loss = 0.42251681078286696\n",
      "80\n",
      "Accuracy = 0.9864072419719986, loss = 0.42189910806004727\n",
      "80\n",
      "Accuracy = 0.9864269986120568, loss = 0.4212858911689875\n",
      "80\n",
      "Accuracy = 0.9864466117770094, loss = 0.4206771275330353\n",
      "80\n",
      "Accuracy = 0.98646608250879, loss = 0.42007278481211463\n",
      "80\n",
      "Accuracy = 0.9864854118417652, loss = 0.41947283090100695\n",
      "80\n",
      "Accuracy = 0.9865046008027903, loss = 0.41887723392764487\n",
      "80\n",
      "Accuracy = 0.9865236504112634, loss = 0.41828596225142095\n",
      "80\n",
      "Accuracy = 0.9865425616791798, loss = 0.4176989844615049\n",
      "80\n",
      "Accuracy = 0.9865613356111849, loss = 0.4171162693751758\n",
      "80\n",
      "Accuracy = 0.9865799732046288, loss = 0.41653778603616554\n",
      "80\n",
      "Accuracy = 0.9865984754496188, loss = 0.41596350371301405\n",
      "80\n",
      "Accuracy = 0.9866168433290714, loss = 0.41539339189743735\n",
      "80\n",
      "Accuracy = 0.9866350778187656, loss = 0.4148274203027051\n",
      "80\n",
      "Accuracy = 0.9866531798873939, loss = 0.41426555886203403\n",
      "80\n",
      "Accuracy = 0.9866711504966139, loss = 0.4137077777269891\n",
      "80\n",
      "Accuracy = 0.9866889906010999, loss = 0.41315404726589816\n",
      "80\n",
      "Accuracy = 0.986706701148593, loss = 0.41260433806227753\n",
      "80\n",
      "Accuracy = 0.9867242830799516, loss = 0.41205862091327017\n",
      "80\n",
      "Accuracy = 0.9867417373292018, loss = 0.4115168668280937\n",
      "80\n",
      "Accuracy = 0.9867590648235863, loss = 0.4109790470264992\n",
      "80\n",
      "Accuracy = 0.9867762664836144, loss = 0.4104451329372454\n",
      "80\n",
      "Accuracy = 0.9867933432231102, loss = 0.4099150961965766\n",
      "80\n",
      "Accuracy = 0.9868102959492617, loss = 0.40938890864671995\n",
      "80\n",
      "Accuracy = 0.986827125562669, loss = 0.4088665423343866\n",
      "80\n",
      "Accuracy = 0.9868438329573916, loss = 0.4083479695092884\n",
      "80\n",
      "Accuracy = 0.9868604190209963, loss = 0.4078331626226627\n",
      "80\n",
      "Accuracy = 0.9868768846346043, loss = 0.4073220943258101\n",
      "80\n",
      "Accuracy = 0.9868932306729382, loss = 0.4068147374686396\n",
      "80\n",
      "Accuracy = 0.9869094580043679, loss = 0.40631106509822856\n",
      "80\n",
      "Accuracy = 0.9869255674909574, loss = 0.40581105045738897\n",
      "80\n",
      "Accuracy = 0.98694155998851, loss = 0.4053146669832472\n",
      "80\n",
      "Accuracy = 0.9869574363466144, loss = 0.4048218883058321\n",
      "80\n",
      "Accuracy = 0.986973197408689, loss = 0.4043326882466748\n",
      "80\n",
      "Accuracy = 0.9869888440120279, loss = 0.4038470408174171\n",
      "80\n",
      "Accuracy = 0.9870043769878439, loss = 0.40336492021843195\n",
      "80\n",
      "Accuracy = 0.987019797161314, loss = 0.4028863008374518\n",
      "80\n",
      "Accuracy = 0.9870351053516225, loss = 0.4024111572482091\n",
      "80\n",
      "Accuracy = 0.9870503023720044, loss = 0.401939464209084\n",
      "80\n",
      "Accuracy = 0.9870653890297894, loss = 0.40147119666176556\n",
      "80\n",
      "Accuracy = 0.9870803661264438, loss = 0.4010063297299181\n",
      "80\n",
      "Accuracy = 0.9870952344576138, loss = 0.40054483871786195\n",
      "80\n",
      "Accuracy = 0.9871099948131675, loss = 0.4000866991092595\n",
      "80\n",
      "Accuracy = 0.987124647977237, loss = 0.3996318865658141\n",
      "80\n",
      "Accuracy = 0.9871391947282596, loss = 0.39918037692597763\n",
      "80\n",
      "Accuracy = 0.9871536358390198, loss = 0.3987321462036644\n",
      "80\n",
      "Accuracy = 0.9871679720766899, loss = 0.3982871705869795\n",
      "80\n",
      "Accuracy = 0.987182204202871, loss = 0.3978454264369535\n",
      "80\n",
      "Accuracy = 0.9871963329736332, loss = 0.3974068902862846\n",
      "80\n",
      "Accuracy = 0.9872103591395561, loss = 0.39697153883809433\n",
      "80\n",
      "Accuracy = 0.9872242834457685, loss = 0.39653934896468923\n",
      "80\n",
      "Accuracy = 0.9872381066319879, loss = 0.3961102977063309\n",
      "80\n",
      "Accuracy = 0.9872518294325596, loss = 0.39568436227001796\n",
      "80\n",
      "Accuracy = 0.9872654525764968, loss = 0.3952615200282744\n",
      "80\n",
      "Accuracy = 0.9872789767875176, loss = 0.39484174851794834\n",
      "80\n",
      "Accuracy = 0.987292402784085, loss = 0.39442502543901664\n",
      "80\n",
      "Accuracy = 0.9873057312794442, loss = 0.39401132865340316\n",
      "80\n",
      "Accuracy = 0.9873189629816607, loss = 0.3936006361837997\n",
      "80\n",
      "Accuracy = 0.9873320985936579, loss = 0.39319292621250085\n",
      "80\n",
      "Accuracy = 0.9873451388132547, loss = 0.39278817708024427\n",
      "80\n",
      "Accuracy = 0.9873580843332023, loss = 0.39238636728505877\n",
      "80\n",
      "Accuracy = 0.9873709358412207, loss = 0.391987475481124\n",
      "80\n",
      "Accuracy = 0.9873836940200362, loss = 0.39159148047763503\n",
      "80\n",
      "Accuracy = 0.9873963595474167, loss = 0.39119836123767693\n",
      "80\n",
      "Accuracy = 0.9874089330962079, loss = 0.39080809687710805\n",
      "80\n",
      "Accuracy = 0.9874214153343696, loss = 0.39042066666344943\n",
      "80\n",
      "Accuracy = 0.9874338069250105, loss = 0.39003605001478375\n",
      "80\n",
      "Accuracy = 0.9874461085264239, loss = 0.389654226498663\n",
      "80\n",
      "Accuracy = 0.9874583207921225, loss = 0.38927517583102056\n",
      "80\n",
      "Accuracy = 0.9874704443708728, loss = 0.38889887787509636\n",
      "80\n",
      "Accuracy = 0.9874824799067305, loss = 0.3885253126403657\n",
      "80\n",
      "Accuracy = 0.9874944280390735, loss = 0.3881544602814768\n",
      "80\n",
      "Accuracy = 0.9875062894026367, loss = 0.38778630109719836\n",
      "80\n",
      "Accuracy = 0.9875180646275454, loss = 0.38742081552937063\n",
      "80\n",
      "Accuracy = 0.9875297543393491, loss = 0.3870579841618682\n",
      "80\n",
      "Accuracy = 0.987541359159054, loss = 0.3866977877195675\n",
      "80\n",
      "Accuracy = 0.9875528797031571, loss = 0.38634020706732436\n",
      "80\n",
      "Accuracy = 0.9875643165836778, loss = 0.3859852232089548\n",
      "80\n",
      "Accuracy = 0.9875756704081912, loss = 0.38563281728622895\n",
      "80\n",
      "Accuracy = 0.98758694177986, loss = 0.38528297057786604\n",
      "80\n",
      "Accuracy = 0.9875981312974667, loss = 0.3849356644985426\n",
      "80\n",
      "Accuracy = 0.9876092395554453, loss = 0.38459088059790425\n",
      "80\n",
      "Accuracy = 0.9876202671439134, loss = 0.38424860055958426\n",
      "80\n",
      "Accuracy = 0.9876312146487023, loss = 0.38390880620023216\n",
      "80\n",
      "Accuracy = 0.9876420826513896, loss = 0.3835714794685476\n",
      "80\n",
      "Accuracy = 0.9876528717293291, loss = 0.3832366024443199\n",
      "80\n",
      "Accuracy = 0.9876635824556819, loss = 0.3829041573374782\n",
      "80\n",
      "Accuracy = 0.9876742153994466, loss = 0.38257412648714456\n",
      "80\n",
      "Accuracy = 0.9876847711254897, loss = 0.3822464923606971\n",
      "80\n",
      "Accuracy = 0.9876952501945757, loss = 0.3819212375528366\n",
      "80\n",
      "Accuracy = 0.9877056531633966, loss = 0.3815983447846652\n",
      "80\n",
      "Accuracy = 0.9877159805846019, loss = 0.3812777969027647\n",
      "80\n",
      "Accuracy = 0.9877262330068274, loss = 0.38095957687828824\n",
      "80\n",
      "Accuracy = 0.9877364109747246, loss = 0.3806436678060546\n",
      "80\n",
      "Accuracy = 0.98774651502899, loss = 0.3803300529036488\n",
      "80\n",
      "Accuracy = 0.9877565457063934, loss = 0.3800187155105327\n",
      "80\n",
      "Accuracy = 0.9877665035398062, loss = 0.379709639087159\n",
      "80\n",
      "Accuracy = 0.9877763890582304, loss = 0.37940280721409214\n",
      "80\n",
      "Accuracy = 0.987786202786826, loss = 0.37909820359113705\n",
      "80\n",
      "Accuracy = 0.9877959452469398, loss = 0.3787958120364726\n",
      "80\n",
      "Accuracy = 0.9878056169561317, loss = 0.378495616485791\n",
      "80\n",
      "Accuracy = 0.9878152184282036, loss = 0.37819760099144706\n",
      "80\n",
      "Accuracy = 0.987824750173226, loss = 0.37790174972160745\n",
      "80\n",
      "Accuracy = 0.9878342126975651, loss = 0.3776080469594132\n",
      "80\n",
      "Accuracy = 0.9878436065039099, loss = 0.3773164771021419\n",
      "80\n",
      "Accuracy = 0.9878529320912988, loss = 0.3770270246603811\n",
      "80\n",
      "Accuracy = 0.9878621899551459, loss = 0.3767396742572034\n",
      "80\n",
      "Accuracy = 0.9878713805872679, loss = 0.3764544106273502\n",
      "80\n",
      "Accuracy = 0.9878805044759096, loss = 0.37617121861642244\n",
      "80\n",
      "Accuracy = 0.9878895621057704, loss = 0.3758900831800728\n",
      "80\n",
      "Accuracy = 0.9878985539580294, loss = 0.37561098938320864\n",
      "80\n",
      "Accuracy = 0.9879074805103716, loss = 0.37533392239919755\n",
      "80\n",
      "Accuracy = 0.9879163422370127, loss = 0.37505886750907996\n",
      "80\n",
      "Accuracy = 0.9879251396087251, loss = 0.3747858101007864\n",
      "80\n",
      "Accuracy = 0.9879338730928617, loss = 0.37451473566836346\n",
      "80\n",
      "Accuracy = 0.9879425431533819, loss = 0.3742456298112005\n",
      "80\n",
      "Accuracy = 0.9879511502508759, loss = 0.3739784782332666\n",
      "80\n",
      "Accuracy = 0.9879596948425885, loss = 0.37371326674234917\n",
      "80\n",
      "Accuracy = 0.9879681773824442, loss = 0.37344998124930356\n",
      "80\n",
      "Accuracy = 0.9879765983210714, loss = 0.373188607767299\n",
      "80\n",
      "Accuracy = 0.9879849581058254, loss = 0.3729291324110814\n",
      "80\n",
      "Accuracy = 0.9879932571808132, loss = 0.3726715413962318\n",
      "80\n",
      "Accuracy = 0.9880014959869162, loss = 0.37241582103843573\n",
      "80\n",
      "Accuracy = 0.9880096749618145, loss = 0.3721619577527561\n",
      "80\n",
      "Accuracy = 0.9880177945400095, loss = 0.37190993805291045\n",
      "80\n",
      "Accuracy = 0.9880258551528472, loss = 0.3716597485505561\n",
      "80\n",
      "Accuracy = 0.9880338572285412, loss = 0.37141137595457774\n",
      "80\n",
      "Accuracy = 0.9880418011921952, loss = 0.3711648070703823\n",
      "80\n",
      "Accuracy = 0.988049687465826, loss = 0.3709200287991964\n",
      "80\n",
      "Accuracy = 0.9880575164683855, loss = 0.37067702813737263\n",
      "80\n",
      "Accuracy = 0.9880652886157829, loss = 0.3704357921756968\n",
      "80\n",
      "Accuracy = 0.9880730043209075, loss = 0.3701963080987037\n",
      "80\n",
      "Accuracy = 0.9880806639936499, loss = 0.36995856318399495\n",
      "80\n",
      "Accuracy = 0.9880882680409239, loss = 0.369722544801564\n",
      "80\n",
      "Accuracy = 0.9880958168666883, loss = 0.36948824041312556\n",
      "80\n",
      "Accuracy = 0.9881033108719687, loss = 0.36925563757144764\n",
      "80\n",
      "Accuracy = 0.9881107504548777, loss = 0.369024723919692\n",
      "80\n",
      "Accuracy = 0.9881181360106374, loss = 0.3687954871907579\n",
      "80\n",
      "Accuracy = 0.9881254679315993, loss = 0.36856791520662946\n",
      "80\n",
      "Accuracy = 0.9881327466072659, loss = 0.36834199587772903\n",
      "80\n",
      "Accuracy = 0.988139972424311, loss = 0.3681177172022743\n",
      "80\n",
      "Accuracy = 0.9881471457666, loss = 0.3678950672656422\n",
      "80\n",
      "Accuracy = 0.9881542670152114, loss = 0.36767403423973427\n",
      "80\n",
      "Accuracy = 0.9881613365484553, loss = 0.36745460638234984\n",
      "80\n",
      "Accuracy = 0.9881683547418952, loss = 0.36723677203656124\n",
      "80\n",
      "Accuracy = 0.9881753219683669, loss = 0.36702051963009513\n",
      "80\n",
      "Accuracy = 0.9881822385979987, loss = 0.366805837674717\n",
      "80\n",
      "Accuracy = 0.9881891049982309, loss = 0.3665927147656211\n",
      "80\n",
      "Accuracy = 0.9881959215338356, loss = 0.3663811395808253\n",
      "80\n",
      "Accuracy = 0.9882026885669356, loss = 0.3661711008805689\n",
      "80\n",
      "Accuracy = 0.988209406457024, loss = 0.36596258750671595\n",
      "80\n",
      "Accuracy = 0.9882160755609836, loss = 0.36575558838216116\n",
      "80\n",
      "Accuracy = 0.9882226962331049, loss = 0.36555009251024384\n",
      "80\n",
      "Accuracy = 0.9882292688251058, loss = 0.3653460889741618\n",
      "80\n",
      "Accuracy = 0.9882357936861499, loss = 0.3651435669363917\n",
      "80\n",
      "Accuracy = 0.9882422711628653, loss = 0.36494251563811414\n",
      "80\n",
      "Accuracy = 0.9882487015993626, loss = 0.36474292439864126\n",
      "80\n",
      "Accuracy = 0.9882550853372537, loss = 0.3645447826148499\n",
      "80\n",
      "Accuracy = 0.9882614227156693, loss = 0.3643480797606175\n",
      "80\n",
      "Accuracy = 0.9882677140712777, loss = 0.3641528053862645\n",
      "80\n",
      "Accuracy = 0.9882739597383019, loss = 0.363958949117997\n",
      "80\n",
      "Accuracy = 0.988280160048538, loss = 0.3637665006573574\n",
      "80\n",
      "Accuracy = 0.9882863153313727, loss = 0.3635754497806768\n",
      "80\n",
      "Accuracy = 0.9882924259138, loss = 0.36338578633853197\n",
      "80\n",
      "Accuracy = 0.98829849212044, loss = 0.36319750025520514\n",
      "80\n",
      "Accuracy = 0.9883045142735548, loss = 0.36301058152815097\n",
      "80\n",
      "Accuracy = 0.9883104926930665, loss = 0.3628250202274629\n",
      "80\n",
      "Accuracy = 0.9883164276965739, loss = 0.36264080649534647\n",
      "80\n",
      "Accuracy = 0.9883223195993691, loss = 0.3624579305455963\n",
      "80\n",
      "Accuracy = 0.9883281687144548, loss = 0.3622763826630752\n",
      "80\n",
      "Accuracy = 0.9883339753525606, loss = 0.3620961532031985\n",
      "80\n",
      "Accuracy = 0.9883397398221592, loss = 0.36191723259142183\n",
      "80\n",
      "Accuracy = 0.9883454624294835, loss = 0.3617396113227323\n",
      "80\n",
      "Accuracy = 0.9883511434785426, loss = 0.36156327996114335\n",
      "80\n",
      "Accuracy = 0.9883567832711373, loss = 0.3613882291391943\n",
      "80\n",
      "Accuracy = 0.9883623821068772, loss = 0.36121444955745086\n",
      "80\n",
      "Accuracy = 0.9883679402831959, loss = 0.361041931984014\n",
      "80\n",
      "Accuracy = 0.988373458095367, loss = 0.36087066725402683\n",
      "80\n",
      "Accuracy = 0.9883789358365199, loss = 0.3607006462691888\n",
      "80\n",
      "Accuracy = 0.9883843737976551, loss = 0.360531859997272\n",
      "80\n",
      "Accuracy = 0.98838977226766, loss = 0.3603642994716428\n",
      "80\n",
      "Accuracy = 0.9883951315333237, loss = 0.3601979557907834\n",
      "80\n",
      "Accuracy = 0.9884004518793531, loss = 0.3600328201178201\n",
      "80\n",
      "Accuracy = 0.9884057335883872, loss = 0.35986888368005376\n",
      "80\n",
      "Accuracy = 0.9884109769410127, loss = 0.35970613776849364\n",
      "80\n",
      "Accuracy = 0.9884161822157781, loss = 0.35954457373739446\n",
      "80\n",
      "Accuracy = 0.9884213496892097, loss = 0.3593841830037976\n",
      "80\n",
      "Accuracy = 0.9884264796358253, loss = 0.3592249570470751\n",
      "80\n",
      "Accuracy = 0.9884315723281492, loss = 0.35906688740847653\n",
      "80\n",
      "Accuracy = 0.9884366280367263, loss = 0.35890996569068045\n",
      "80\n",
      "Accuracy = 0.9884416470301374, loss = 0.3587541835573469\n",
      "80\n",
      "Accuracy = 0.9884466295750123, loss = 0.3585995327326759\n",
      "80\n",
      "Accuracy = 0.9884515759360446, loss = 0.35844600500096757\n",
      "80\n",
      "Accuracy = 0.9884564863760059, loss = 0.3582935922061852\n",
      "80\n",
      "Accuracy = 0.9884613611557592, loss = 0.35814228625152256\n",
      "80\n",
      "Accuracy = 0.9884662005342735, loss = 0.3579920790989719\n",
      "80\n",
      "Accuracy = 0.9884710047686365, loss = 0.3578429627689007\n",
      "80\n",
      "Accuracy = 0.9884757741140695, loss = 0.35769492933962393\n",
      "80\n",
      "Accuracy = 0.9884805088239401, loss = 0.35754797094698576\n",
      "80\n",
      "Accuracy = 0.9884852091497759, loss = 0.3574020797839392\n",
      "80\n",
      "Accuracy = 0.9884898753412779, loss = 0.3572572481001353\n",
      "80\n",
      "Accuracy = 0.9884945076463337, loss = 0.35711346820150724\n",
      "80\n",
      "Accuracy = 0.988499106311031, loss = 0.3569707324498644\n",
      "80\n",
      "Accuracy = 0.9885036715796699, loss = 0.35682903326248483\n",
      "80\n",
      "Accuracy = 0.9885082036947768, loss = 0.35668836311171426\n",
      "80\n",
      "Accuracy = 0.9885127028971163, loss = 0.356548714524564\n",
      "80\n",
      "Accuracy = 0.9885171694257053, loss = 0.35641008008231606\n",
      "80\n",
      "Accuracy = 0.9885216035178245, loss = 0.35627245242012784\n",
      "80\n",
      "Accuracy = 0.9885260054090311, loss = 0.35613582422664053\n",
      "80\n",
      "Accuracy = 0.9885303753331723, loss = 0.35600018824359214\n",
      "80\n",
      "Accuracy = 0.9885347135223967, loss = 0.3558655372654303\n",
      "80\n",
      "Accuracy = 0.9885390202071672, loss = 0.35573186413893065\n",
      "80\n",
      "Accuracy = 0.9885432956162729, loss = 0.3555991617628168\n",
      "80\n",
      "Accuracy = 0.9885475399768413, loss = 0.3554674230873819\n",
      "80\n",
      "Accuracy = 0.9885517535143509, loss = 0.3553366411141149\n",
      "80\n",
      "Accuracy = 0.9885559364526422, loss = 0.3552068088953297\n",
      "80\n",
      "Accuracy = 0.9885600890139306, loss = 0.3550779195337944\n",
      "80\n",
      "Accuracy = 0.9885642114188175, loss = 0.3549499661823655\n",
      "80\n",
      "Accuracy = 0.9885683038863022, loss = 0.35482294204362497\n",
      "80\n",
      "Accuracy = 0.9885723666337941, loss = 0.35469684036951815\n",
      "80\n",
      "Accuracy = 0.988576399877123, loss = 0.354571654460995\n",
      "80\n",
      "Accuracy = 0.9885804038305519, loss = 0.3544473776676559\n",
      "80\n",
      "Accuracy = 0.9885843787067875, loss = 0.3543240033873957\n",
      "80\n",
      "Accuracy = 0.9885883247169919, loss = 0.3542015250660564\n",
      "80\n",
      "Accuracy = 0.9885922420707938, loss = 0.35407993619707556\n",
      "80\n",
      "Accuracy = 0.9885961309762993, loss = 0.35395923032114307\n",
      "80\n",
      "Accuracy = 0.9885999916401035, loss = 0.3538394010258564\n",
      "80\n",
      "Accuracy = 0.9886038242673009, loss = 0.3537204419453818\n",
      "80\n",
      "Accuracy = 0.9886076290614968, loss = 0.3536023467601134\n",
      "80\n",
      "Accuracy = 0.9886114062248179, loss = 0.35348510919634024\n",
      "80\n",
      "Accuracy = 0.9886151559579229, loss = 0.3533687230259114\n",
      "80\n",
      "Accuracy = 0.9886188784600133, loss = 0.3532531820659059\n",
      "80\n",
      "Accuracy = 0.988622573928844, loss = 0.35313848017830324\n",
      "80\n",
      "Accuracy = 0.9886262425607338, loss = 0.3530246112696581\n",
      "80\n",
      "Accuracy = 0.9886298845505759, loss = 0.35291156929077727\n",
      "80\n",
      "Accuracy = 0.9886335000918479, loss = 0.3527993482363968\n",
      "80\n",
      "Accuracy = 0.9886370893766228, loss = 0.3526879421448638\n",
      "80\n",
      "Accuracy = 0.9886406525955781, loss = 0.35257734509781946\n",
      "80\n",
      "Accuracy = 0.9886441899380071, loss = 0.35246755121988554\n",
      "80\n",
      "Accuracy = 0.9886477015918284, loss = 0.3523585546783501\n",
      "80\n",
      "Accuracy = 0.9886511877435954, loss = 0.3522503496828607\n",
      "80\n",
      "Accuracy = 0.9886546485785075, loss = 0.35214293048511414\n",
      "80\n",
      "Accuracy = 0.9886580842804185, loss = 0.35203629137855225\n",
      "80\n",
      "Accuracy = 0.9886614950318473, loss = 0.35193042669805874\n",
      "80\n",
      "Accuracy = 0.9886648810139875, loss = 0.35182533081965794\n",
      "80\n",
      "Accuracy = 0.9886682424067166, loss = 0.3517209981602163\n",
      "80\n",
      "Accuracy = 0.9886715793886056, loss = 0.3516174231771451\n",
      "80\n",
      "Accuracy = 0.9886748921369294, loss = 0.3515146003681082\n",
      "80\n",
      "Accuracy = 0.9886781808276748, loss = 0.3514125242707259\n",
      "80\n",
      "Accuracy = 0.9886814456355508, loss = 0.35131118946228845\n",
      "80\n",
      "Accuracy = 0.9886846867339979, loss = 0.3512105905594655\n",
      "80\n",
      "Accuracy = 0.9886879042951967, loss = 0.3511107222180224\n",
      "80\n",
      "Accuracy = 0.9886910984900775, loss = 0.3510115791325335\n",
      "80\n",
      "Accuracy = 0.9886942694883295, loss = 0.35091315603610296\n",
      "80\n",
      "Accuracy = 0.9886974174584092, loss = 0.3508154477000832\n",
      "80\n",
      "Accuracy = 0.9887005425675501, loss = 0.35071844893379733\n",
      "80\n",
      "Accuracy = 0.988703644981771, loss = 0.3506221545842654\n",
      "80\n",
      "Accuracy = 0.9887067248658853, loss = 0.3505265595359265\n",
      "80\n",
      "Accuracy = 0.9887097823835093, loss = 0.3504316587103718\n",
      "80\n",
      "Accuracy = 0.9887128176970711, loss = 0.35033744706607156\n",
      "80\n",
      "Accuracy = 0.9887158309678192, loss = 0.3502439195981081\n",
      "80\n",
      "Accuracy = 0.9887188223558314, loss = 0.3501510713379102\n",
      "80\n",
      "Accuracy = 0.9887217920200225, loss = 0.35005889735298923\n",
      "80\n",
      "Accuracy = 0.9887247401181538, loss = 0.3499673927466767\n",
      "80\n",
      "Accuracy = 0.9887276668068405, loss = 0.34987655265786405\n",
      "80\n",
      "Accuracy = 0.9887305722415606, loss = 0.3497863722607451\n",
      "80\n",
      "Accuracy = 0.9887334565766628, loss = 0.34969684676455914\n",
      "80\n",
      "Accuracy = 0.9887363199653753, loss = 0.34960797141333677\n",
      "80\n",
      "Accuracy = 0.9887391625598132, loss = 0.34951974148564635\n",
      "80\n",
      "Accuracy = 0.988741984510987, loss = 0.34943215229434477\n",
      "80\n",
      "Accuracy = 0.9887447859688107, loss = 0.34934519918632634\n",
      "80\n",
      "Accuracy = 0.9887475670821093, loss = 0.34925887754227786\n",
      "80\n",
      "Accuracy = 0.9887503279986275, loss = 0.34917318277643183\n",
      "80\n",
      "Accuracy = 0.9887530688650364, loss = 0.3490881103363229\n",
      "80\n",
      "Accuracy = 0.9887557898269426, loss = 0.3490036557025463\n",
      "80\n",
      "Accuracy = 0.9887584910288948, loss = 0.34891981438851777\n",
      "80\n",
      "Accuracy = 0.9887611726143923, loss = 0.3488365819402356\n",
      "80\n",
      "Accuracy = 0.9887638347258921, loss = 0.3487539539360429\n",
      "80\n",
      "Accuracy = 0.9887664775048167, loss = 0.34867192598639385\n",
      "80\n",
      "Accuracy = 0.9887691010915618, loss = 0.34859049373361994\n",
      "80\n",
      "Accuracy = 0.988771705625503, loss = 0.3485096528516986\n",
      "80\n",
      "Accuracy = 0.9887742912450043, loss = 0.34842939904602327\n",
      "80\n",
      "Accuracy = 0.9887768580874245, loss = 0.348349728053175\n",
      "80\n",
      "Accuracy = 0.9887794062891252, loss = 0.3482706356406973\n",
      "80\n",
      "Accuracy = 0.9887819359854774, loss = 0.34819211760686897\n",
      "80\n",
      "Accuracy = 0.9887844473108692, loss = 0.34811416978048326\n",
      "80\n",
      "Accuracy = 0.9887869403987128, loss = 0.3480367880206251\n",
      "80\n",
      "Accuracy = 0.9887894153814515, loss = 0.34795996821645025\n",
      "80\n",
      "Accuracy = 0.9887918723905667, loss = 0.3478837062869698\n",
      "80\n",
      "Accuracy = 0.9887943115565849, loss = 0.34780799818082936\n",
      "80\n",
      "Accuracy = 0.9887967330090851, loss = 0.34773283987609765\n",
      "80\n",
      "Accuracy = 0.9887991368767047, loss = 0.3476582273800498\n",
      "80\n",
      "Accuracy = 0.9888015232871475, loss = 0.3475841567289578\n",
      "80\n",
      "Accuracy = 0.9888038923671896, loss = 0.3475106239878777\n",
      "80\n",
      "Accuracy = 0.9888062442426861, loss = 0.34743762525044264\n",
      "80\n",
      "Accuracy = 0.988808579038579, loss = 0.34736515663865314\n",
      "80\n",
      "Accuracy = 0.9888108968789021, loss = 0.3472932143026731\n",
      "80\n",
      "Accuracy = 0.9888131978867889, loss = 0.3472217944206236\n",
      "80\n",
      "Accuracy = 0.9888154821844787, loss = 0.34715089319838155\n",
      "80\n",
      "Accuracy = 0.9888177498933227, loss = 0.34708050686937647\n",
      "80\n",
      "Accuracy = 0.9888200011337913, loss = 0.34701063169439184\n",
      "80\n",
      "Accuracy = 0.9888222360254798, loss = 0.3469412639613652\n",
      "80\n",
      "Accuracy = 0.9888244546871149, loss = 0.3468723999851919\n",
      "80\n",
      "Accuracy = 0.9888266572365614, loss = 0.3468040361075288\n",
      "80\n",
      "Accuracy = 0.9888288437908279, loss = 0.34673616869659984\n",
      "80\n",
      "Accuracy = 0.9888310144660732, loss = 0.34666879414700413\n",
      "80\n",
      "Accuracy = 0.9888331693776129, loss = 0.34660190887952297\n",
      "80\n",
      "Accuracy = 0.9888353086399246, loss = 0.3465355093409307\n",
      "80\n",
      "Accuracy = 0.9888374323666552, loss = 0.3464695920038049\n",
      "80\n",
      "Accuracy = 0.9888395406706258, loss = 0.3464041533663411\n",
      "80\n",
      "Accuracy = 0.9888416336638385, loss = 0.346339189952164\n",
      "80\n",
      "Accuracy = 0.9888437114574816, loss = 0.34627469831014507\n",
      "80\n",
      "Accuracy = 0.9888457741619365, loss = 0.34621067501421776\n",
      "80\n",
      "Accuracy = 0.9888478218867826, loss = 0.34614711666319586\n",
      "80\n",
      "Accuracy = 0.9888498547408036, loss = 0.346084019880594\n",
      "80\n",
      "Accuracy = 0.9888518728319932, loss = 0.34602138131444604\n",
      "80\n",
      "Accuracy = 0.9888538762675608, loss = 0.3459591976371289\n",
      "80\n",
      "Accuracy = 0.9888558651539374, loss = 0.3458974655451851\n",
      "80\n",
      "Accuracy = 0.9888578395967811, loss = 0.3458361817591468\n",
      "80\n",
      "Accuracy = 0.9888597997009825, loss = 0.3457753430233631\n",
      "80\n",
      "Accuracy = 0.9888617455706704, loss = 0.3457149461058247\n",
      "80\n",
      "Accuracy = 0.9888636773092176, loss = 0.3456549877979941\n",
      "80\n",
      "Accuracy = 0.9888655950192464, loss = 0.34559546491463505\n",
      "80\n",
      "Accuracy = 0.9888674988026332, loss = 0.34553637429364226\n",
      "80\n",
      "Accuracy = 0.9888693887605153, loss = 0.345477712795874\n",
      "80\n",
      "Accuracy = 0.9888712649932951, loss = 0.3454194773049861\n",
      "80\n",
      "Accuracy = 0.9888731276006458, loss = 0.34536166472726454\n",
      "80\n",
      "Accuracy = 0.9888749766815171, loss = 0.3453042719914636\n",
      "80\n",
      "Accuracy = 0.9888768123341398, loss = 0.3452472960486397\n",
      "80\n",
      "Accuracy = 0.9888786346560314, loss = 0.3451907338719928\n",
      "80\n",
      "Accuracy = 0.9888804437440015, loss = 0.345134582456702\n",
      "80\n",
      "Accuracy = 0.9888822396941563, loss = 0.34507883881976964\n",
      "80\n",
      "Accuracy = 0.9888840226019042, loss = 0.34502349999985943\n",
      "80\n",
      "Accuracy = 0.9888857925619609, loss = 0.3449685630571412\n",
      "80\n",
      "Accuracy = 0.9888875496683537, loss = 0.34491402507313496\n",
      "80\n",
      "Accuracy = 0.9888892940144278, loss = 0.3448598831505537\n",
      "80\n",
      "Accuracy = 0.9888910256928501, loss = 0.3448061344131521\n",
      "80\n",
      "Accuracy = 0.9888927447956146, loss = 0.3447527760055714\n",
      "80\n",
      "Accuracy = 0.9888944514140472, loss = 0.3446998050931894\n",
      "80\n",
      "Accuracy = 0.9888961456388108, loss = 0.3446472188619694\n",
      "80\n",
      "Accuracy = 0.9888978275599094, loss = 0.3445950145183102\n",
      "80\n",
      "Accuracy = 0.988899497266694, loss = 0.3445431892888985\n",
      "80\n",
      "Accuracy = 0.9889011548478663, loss = 0.34449174042055997\n",
      "80\n",
      "Accuracy = 0.988902800391484, loss = 0.34444066518011623\n",
      "80\n",
      "Accuracy = 0.9889044339849653, loss = 0.3443899608542357\n",
      "80\n",
      "Accuracy = 0.9889060557150934, loss = 0.3443396247492923\n",
      "80\n",
      "Accuracy = 0.9889076656680215, loss = 0.3442896541912209\n",
      "80\n",
      "Accuracy = 0.988909263929277, loss = 0.3442400465253758\n",
      "80\n",
      "Accuracy = 0.9889108505837664, loss = 0.34419079911639033\n",
      "80\n",
      "Accuracy = 0.9889124257157792, loss = 0.3441419093480355\n",
      "80\n",
      "Accuracy = 0.9889139894089932, loss = 0.34409337462308176\n",
      "80\n",
      "Accuracy = 0.9889155417464782, loss = 0.3440451923631612\n",
      "80\n",
      "Accuracy = 0.988917082810701, loss = 0.3439973600086301\n",
      "80\n",
      "Accuracy = 0.9889186126835293, loss = 0.34394987501843344\n",
      "80\n",
      "Accuracy = 0.9889201314462364, loss = 0.343902734869969\n",
      "80\n",
      "Accuracy = 0.9889216391795054, loss = 0.3438559370589551\n",
      "80\n",
      "Accuracy = 0.9889231359634332, loss = 0.34380947909929555\n",
      "80\n",
      "Accuracy = 0.9889246218775355, loss = 0.3437633585229485\n",
      "80\n",
      "Accuracy = 0.9889260970007501, loss = 0.343717572879796\n",
      "80\n",
      "Accuracy = 0.9889275614114418, loss = 0.3436721197375124\n",
      "80\n",
      "Accuracy = 0.9889290151874063, loss = 0.34362699668143704\n",
      "80\n",
      "Accuracy = 0.9889304584058741, loss = 0.3435822013144429\n",
      "80\n",
      "Accuracy = 0.9889318911435152, loss = 0.343537731256813\n",
      "80\n",
      "Accuracy = 0.9889333134764425, loss = 0.3434935841461114\n",
      "80\n",
      "Accuracy = 0.9889347254802163, loss = 0.34344975763705826\n",
      "80\n",
      "Accuracy = 0.9889361272298484, loss = 0.343406249401406\n",
      "80\n",
      "Accuracy = 0.9889375187998052, loss = 0.3433630571278146\n",
      "80\n",
      "Accuracy = 0.988938900264013, loss = 0.3433201785217294\n",
      "80\n",
      "Accuracy = 0.988940271695861, loss = 0.3432776113052591\n",
      "80\n",
      "Accuracy = 0.9889416331682052, loss = 0.3432353532170544\n",
      "80\n",
      "Accuracy = 0.988942984753373, loss = 0.3431934020121893\n",
      "80\n",
      "Accuracy = 0.9889443265231659, loss = 0.3431517554620391\n",
      "80\n",
      "Accuracy = 0.9889456585488646, loss = 0.34311041135416526\n",
      "80\n",
      "Accuracy = 0.9889469809012319, loss = 0.3430693674921949\n",
      "80\n",
      "Accuracy = 0.9889482936505166, loss = 0.343028621695706\n",
      "80\n",
      "Accuracy = 0.9889495968664576, loss = 0.3429881718001112\n",
      "80\n",
      "Accuracy = 0.9889508906182869, loss = 0.3429480156565426\n",
      "80\n",
      "Accuracy = 0.9889521749747343, loss = 0.3429081511317373\n",
      "80\n",
      "Accuracy = 0.9889534500040301, loss = 0.3428685761079245\n",
      "80\n",
      "Accuracy = 0.9889547157739091, loss = 0.3428292884827137\n",
      "80\n",
      "Accuracy = 0.9889559723516145, loss = 0.34279028616898105\n",
      "80\n",
      "Accuracy = 0.9889572198039008, loss = 0.34275156709475996\n",
      "80\n",
      "Accuracy = 0.9889584581970381, loss = 0.3427131292031312\n",
      "80\n",
      "Accuracy = 0.9889596875968147, loss = 0.3426749704521127\n",
      "80\n",
      "Accuracy = 0.9889609080685419, loss = 0.3426370888145519\n",
      "80\n",
      "Accuracy = 0.9889621196770559, loss = 0.3425994822780169\n",
      "80\n",
      "Accuracy = 0.9889633224867226, loss = 0.3425621488446914\n",
      "80\n",
      "Accuracy = 0.9889645165614402, loss = 0.34252508653126634\n",
      "80\n",
      "Accuracy = 0.9889657019646432, loss = 0.34248829336883724\n",
      "80\n",
      "Accuracy = 0.9889668787593049, loss = 0.3424517674027959\n",
      "80\n",
      "Accuracy = 0.9889680470079416, loss = 0.3424155066927306\n",
      "80\n",
      "Accuracy = 0.9889692067726157, loss = 0.34237950931232003\n",
      "80\n",
      "Accuracy = 0.9889703581149387, loss = 0.3423437733492328\n",
      "80\n",
      "Accuracy = 0.9889715010960748, loss = 0.3423082969050244\n",
      "80\n",
      "Accuracy = 0.9889726357767438, loss = 0.34227307809503793\n",
      "80\n",
      "Accuracy = 0.9889737622172247, loss = 0.3422381150483019\n",
      "80\n",
      "Accuracy = 0.9889748804773589, loss = 0.3422034059074331\n",
      "80\n",
      "Accuracy = 0.988975990616553, loss = 0.3421689488285364\n",
      "80\n",
      "Accuracy = 0.9889770926937821, loss = 0.34213474198110694\n",
      "80\n",
      "Accuracy = 0.9889781867675934, loss = 0.3421007835479345\n",
      "80\n",
      "Accuracy = 0.9889792728961085, loss = 0.3420670717250037\n",
      "80\n",
      "Accuracy = 0.9889803511370273, loss = 0.34203360472140193\n",
      "80\n",
      "Accuracy = 0.9889814215476302, loss = 0.34200038075922135\n",
      "80\n",
      "Accuracy = 0.9889824841847822, loss = 0.34196739807346593\n",
      "80\n",
      "Accuracy = 0.9889835391049348, loss = 0.341934654911957\n",
      "80\n",
      "Accuracy = 0.9889845863641299, loss = 0.34190214953524045\n",
      "80\n",
      "Accuracy = 0.9889856260180022, loss = 0.34186988021649467\n",
      "80\n",
      "Accuracy = 0.9889866581217827, loss = 0.34183784524143845\n",
      "80\n",
      "Accuracy = 0.9889876827303007, loss = 0.3418060429082389\n",
      "80\n",
      "Accuracy = 0.9889886998979881, loss = 0.34177447152742324\n",
      "80\n",
      "Accuracy = 0.9889897096788809, loss = 0.3417431294217872\n",
      "80\n",
      "Accuracy = 0.9889907121266228, loss = 0.34171201492630676\n",
      "80\n",
      "Accuracy = 0.9889917072944683, loss = 0.34168112638804976\n",
      "80\n",
      "Accuracy = 0.9889926952352848, loss = 0.3416504621660871\n",
      "80\n",
      "Accuracy = 0.9889936760015556, loss = 0.3416200206314072\n",
      "80\n",
      "Accuracy = 0.9889946496453834, loss = 0.34158980016682794\n",
      "80\n",
      "Accuracy = 0.9889956162184922, loss = 0.34155979916691104\n",
      "80\n",
      "Accuracy = 0.9889965757722303, loss = 0.3415300160378783\n",
      "80\n",
      "Accuracy = 0.9889975283575734, loss = 0.3415004491975254\n",
      "80\n",
      "Accuracy = 0.9889984740251266, loss = 0.34147109707513673\n",
      "80\n",
      "Accuracy = 0.9889994128251279, loss = 0.3414419581114051\n",
      "80\n",
      "Accuracy = 0.9890003448074502, loss = 0.3414130307583466\n",
      "80\n",
      "Accuracy = 0.9890012700216043, loss = 0.34138431347921927\n",
      "80\n",
      "Accuracy = 0.9890021885167416, loss = 0.3413558047484402\n",
      "80\n",
      "Accuracy = 0.9890031003416563, loss = 0.34132750305150644\n",
      "80\n",
      "Accuracy = 0.9890040055447883, loss = 0.34129940688491334\n",
      "80\n",
      "Accuracy = 0.9890049041742259, loss = 0.3412715147560745\n",
      "80\n",
      "Accuracy = 0.989005796277708, loss = 0.3412438251832432\n",
      "80\n",
      "Accuracy = 0.9890066819026269, loss = 0.3412163366954332\n",
      "80\n",
      "Accuracy = 0.9890075610960306, loss = 0.34118904783234116\n",
      "80\n",
      "Accuracy = 0.9890084339046258, loss = 0.3411619571442679\n",
      "80\n",
      "Accuracy = 0.9890093003747795, loss = 0.34113506319204245\n",
      "80\n",
      "Accuracy = 0.9890101605525223, loss = 0.34110836454694554\n",
      "80\n",
      "Accuracy = 0.9890110144835506, loss = 0.34108185979063327\n",
      "80\n",
      "Accuracy = 0.9890118622132286, loss = 0.3410555475150616\n",
      "80\n",
      "Accuracy = 0.9890127037865912, loss = 0.3410294263224123\n",
      "80\n",
      "Accuracy = 0.9890135392483466, loss = 0.34100349482501824\n",
      "80\n",
      "Accuracy = 0.9890143686428777, loss = 0.34097775164528926\n",
      "80\n",
      "Accuracy = 0.9890151920142456, loss = 0.3409521954156402\n",
      "80\n",
      "Accuracy = 0.9890160094061913, loss = 0.3409268247784162\n",
      "80\n",
      "Accuracy = 0.9890168208621378, loss = 0.34090163838582355\n",
      "80\n",
      "Accuracy = 0.9890176264251934, loss = 0.34087663489985515\n",
      "80\n",
      "Accuracy = 0.9890184261381528, loss = 0.3408518129922208\n",
      "80\n",
      "Accuracy = 0.9890192200435001, loss = 0.3408271713442773\n",
      "80\n",
      "Accuracy = 0.989020008183411, loss = 0.340802708646956\n",
      "80\n",
      "Accuracy = 0.9890207905997546, loss = 0.34077842360069704\n",
      "80\n",
      "Accuracy = 0.9890215673340962, loss = 0.340754314915376\n",
      "80\n",
      "Accuracy = 0.9890223384276993, loss = 0.3407303813102389\n",
      "80\n",
      "Accuracy = 0.9890231039215275, loss = 0.34070662151383235\n",
      "80\n",
      "Accuracy = 0.9890238638562471, loss = 0.34068303426393653\n",
      "80\n",
      "Accuracy = 0.989024618272229, loss = 0.34065961830749714\n",
      "80\n",
      "Accuracy = 0.9890253672095509, loss = 0.34063637240056127\n",
      "80\n",
      "Accuracy = 0.9890261107079996, loss = 0.34061329530820805\n",
      "80\n",
      "Accuracy = 0.9890268488070728, loss = 0.34059038580448614\n",
      "80\n",
      "Accuracy = 0.9890275815459814, loss = 0.34056764267234685\n",
      "80\n",
      "Accuracy = 0.9890283089636515, loss = 0.34054506470357887\n",
      "80\n",
      "Accuracy = 0.9890290310987268, loss = 0.34052265069874654\n",
      "80\n",
      "Accuracy = 0.9890297479895698, loss = 0.34050039946712374\n",
      "80\n",
      "Accuracy = 0.989030459674265, loss = 0.34047830982663196\n",
      "80\n",
      "Accuracy = 0.98903116619062, loss = 0.3404563806037765\n",
      "80\n",
      "Accuracy = 0.989031867576168, loss = 0.3404346106335853\n",
      "80\n",
      "Accuracy = 0.9890325638681694, loss = 0.3404129987595468\n",
      "80\n",
      "Accuracy = 0.9890332551036142, loss = 0.34039154383354675\n",
      "80\n",
      "Accuracy = 0.9890339413192237, loss = 0.3403702447158097\n",
      "80\n",
      "Accuracy = 0.9890346225514527, loss = 0.340349100274838\n",
      "80\n",
      "Accuracy = 0.9890352988364909, loss = 0.3403281093873498\n",
      "80\n",
      "Accuracy = 0.9890359702102655, loss = 0.3403072709382209\n",
      "80\n",
      "Accuracy = 0.9890366367084427, loss = 0.34028658382042587\n",
      "80\n",
      "Accuracy = 0.9890372983664297, loss = 0.3402660469349781\n",
      "80\n",
      "Accuracy = 0.9890379552193764, loss = 0.34024565919087224\n",
      "80\n",
      "Accuracy = 0.9890386073021777, loss = 0.34022541950502616\n",
      "80\n",
      "Accuracy = 0.9890392546494751, loss = 0.34020532680222243\n",
      "80\n",
      "Accuracy = 0.9890398972956582, loss = 0.3401853800150525\n",
      "80\n",
      "Accuracy = 0.989040535274867, loss = 0.34016557808385983\n",
      "80\n",
      "Accuracy = 0.9890411686209939, loss = 0.34014591995668214\n",
      "80\n",
      "Accuracy = 0.9890417973676847, loss = 0.3401264045891981\n",
      "80\n",
      "Accuracy = 0.9890424215483411, loss = 0.34010703094466876\n",
      "80\n",
      "Accuracy = 0.9890430411961222, loss = 0.34008779799388567\n",
      "80\n",
      "Accuracy = 0.9890436563439463, loss = 0.3400687047151133\n",
      "80\n",
      "Accuracy = 0.9890442670244927, loss = 0.3400497500940372\n",
      "80\n",
      "Accuracy = 0.9890448732702031, loss = 0.34003093312370763\n",
      "80\n",
      "Accuracy = 0.989045475113284, loss = 0.34001225280448893\n",
      "80\n",
      "Accuracy = 0.9890460725857078, loss = 0.33999370814400404\n",
      "80\n",
      "Accuracy = 0.9890466657192146, loss = 0.33997529815708305\n",
      "80\n",
      "Accuracy = 0.9890472545453144, loss = 0.33995702186570964\n",
      "80\n",
      "Accuracy = 0.9890478390952879, loss = 0.33993887829897124\n",
      "80\n",
      "Accuracy = 0.989048419400189, loss = 0.339920866493005\n",
      "80\n",
      "Accuracy = 0.9890489954908457, loss = 0.33990298549094894\n",
      "80\n",
      "Accuracy = 0.9890495673978625, loss = 0.33988523434288886\n",
      "80\n",
      "Accuracy = 0.9890501351516215, loss = 0.33986761210580946\n",
      "80\n",
      "Accuracy = 0.9890506987822842, loss = 0.33985011784354346\n",
      "80\n",
      "Accuracy = 0.989051258319793, loss = 0.33983275062672236\n",
      "80\n",
      "Accuracy = 0.9890518137938727, loss = 0.339815509532727\n",
      "80\n",
      "Accuracy = 0.9890523652340327, loss = 0.33979839364563813\n",
      "80\n",
      "Accuracy = 0.9890529126695676, loss = 0.33978140205618795\n",
      "80\n",
      "Accuracy = 0.9890534561295596, loss = 0.339764533861712\n",
      "80\n",
      "Accuracy = 0.9890539956428795, loss = 0.33974778816610146\n",
      "80\n",
      "Accuracy = 0.9890545312381885, loss = 0.3397311640797541\n",
      "80\n",
      "Accuracy = 0.9890550629439397, loss = 0.3397146607195294\n",
      "80\n",
      "Accuracy = 0.9890555907883796, loss = 0.33969827720869905\n",
      "80\n",
      "Accuracy = 0.9890561147995494, loss = 0.3396820126769028\n",
      "80\n",
      "Accuracy = 0.9890566350052867, loss = 0.3396658662601005\n",
      "80\n",
      "Accuracy = 0.9890571514332273, loss = 0.33964983710052654\n",
      "80\n",
      "Accuracy = 0.9890576641108058, loss = 0.339633924346645\n",
      "80\n",
      "Accuracy = 0.9890581730652577, loss = 0.3396181271531036\n",
      "80\n",
      "Accuracy = 0.989058678323621, loss = 0.33960244468068906\n",
      "80\n",
      "Accuracy = 0.9890591799127371, loss = 0.3395868760962827\n",
      "80\n",
      "Accuracy = 0.9890596778592524, loss = 0.3395714205728164\n",
      "80\n",
      "Accuracy = 0.98906017218962, loss = 0.33955607728922765\n",
      "80\n",
      "Accuracy = 0.9890606629301008, loss = 0.33954084543041685\n",
      "80\n",
      "Accuracy = 0.9890611501067649, loss = 0.33952572418720417\n",
      "80\n",
      "Accuracy = 0.9890616337454933, loss = 0.33951071275628564\n",
      "80\n",
      "Accuracy = 0.9890621138719788, loss = 0.33949581034019116\n",
      "80\n",
      "Accuracy = 0.9890625905117278, loss = 0.3394810161472415\n",
      "80\n",
      "Accuracy = 0.9890630636900615, loss = 0.3394663293915076\n",
      "80\n",
      "Accuracy = 0.989063533432117, loss = 0.3394517492927671\n",
      "80\n",
      "Accuracy = 0.9890639997628489, loss = 0.33943727507646404\n",
      "80\n",
      "Accuracy = 0.9890644627070306, loss = 0.3394229059736679\n",
      "80\n",
      "Accuracy = 0.9890649222892559, loss = 0.33940864122103115\n",
      "80\n",
      "Accuracy = 0.9890653785339396, loss = 0.3393944800607503\n",
      "80\n",
      "Accuracy = 0.9890658314653192, loss = 0.33938042174052574\n",
      "80\n",
      "Accuracy = 0.9890662811074565, loss = 0.3393664655135198\n",
      "80\n",
      "Accuracy = 0.9890667274842383, loss = 0.3393526106383196\n",
      "80\n",
      "Accuracy = 0.9890671706193781, loss = 0.3393388563788961\n",
      "80\n",
      "Accuracy = 0.9890676105364169, loss = 0.33932520200456556\n",
      "80\n",
      "Accuracy = 0.9890680472587251, loss = 0.33931164678995007\n",
      "80\n",
      "Accuracy = 0.989068480809503, loss = 0.33929819001493977\n",
      "80\n",
      "Accuracy = 0.989068911211783, loss = 0.3392848309646546\n",
      "80\n",
      "Accuracy = 0.9890693384884296, loss = 0.3392715689294058\n",
      "80\n",
      "Accuracy = 0.9890697626621416, loss = 0.33925840320465805\n",
      "80\n",
      "Accuracy = 0.989070183755453, loss = 0.33924533309099314\n",
      "80\n",
      "Accuracy = 0.9890706017907338, loss = 0.3392323578940718\n",
      "80\n",
      "Accuracy = 0.9890710167901918, loss = 0.33921947692459764\n",
      "80\n",
      "Accuracy = 0.9890714287758738, loss = 0.33920668949827915\n",
      "80\n",
      "Accuracy = 0.989071837769666, loss = 0.3391939949357944\n",
      "80\n",
      "Accuracy = 0.989072243793296, loss = 0.33918139256275526\n",
      "80\n",
      "Accuracy = 0.9890726468683332, loss = 0.33916888170967086\n",
      "80\n",
      "Accuracy = 0.9890730470161908, loss = 0.3391564617119124\n",
      "80\n",
      "Accuracy = 0.9890734442581264, loss = 0.3391441319096772\n",
      "80\n",
      "Accuracy = 0.9890738386152431, loss = 0.33913189164795454\n",
      "80\n",
      "Accuracy = 0.9890742301084908, loss = 0.3391197402764906\n",
      "80\n",
      "Accuracy = 0.9890746187586673, loss = 0.33910767714975354\n",
      "80\n",
      "Accuracy = 0.9890750045864193, loss = 0.33909570162689934\n",
      "80\n",
      "Accuracy = 0.9890753876122435, loss = 0.3390838130717383\n",
      "80\n",
      "Accuracy = 0.989075767856488, loss = 0.3390720108527\n",
      "80\n",
      "Accuracy = 0.9890761453393527, loss = 0.33906029434280194\n",
      "80\n",
      "Accuracy = 0.9890765200808914, loss = 0.33904866291961316\n",
      "80\n",
      "Accuracy = 0.9890768921010118, loss = 0.3390371159652243\n",
      "80\n",
      "Accuracy = 0.9890772614194772, loss = 0.3390256528662125\n",
      "80\n",
      "Accuracy = 0.9890776280559073, loss = 0.33901427301360954\n",
      "80\n",
      "Accuracy = 0.9890779920297793, loss = 0.33900297580287064\n",
      "80\n",
      "Accuracy = 0.9890783533604292, loss = 0.33899176063383984\n",
      "80\n",
      "Accuracy = 0.9890787120670521, loss = 0.3389806269107212\n",
      "80\n",
      "Accuracy = 0.9890790681687043, loss = 0.338969574042044\n",
      "80\n",
      "Accuracy = 0.9890794216843033, loss = 0.3389586014406338\n",
      "80\n",
      "Accuracy = 0.9890797726326294, loss = 0.3389477085235798\n",
      "80\n",
      "Accuracy = 0.9890801210323262, loss = 0.3389368947122052\n",
      "80\n",
      "Accuracy = 0.9890804669019025, loss = 0.3389261594320343\n",
      "80\n",
      "Accuracy = 0.9890808102597322, loss = 0.33891550211276417\n",
      "80\n",
      "Accuracy = 0.9890811511240558, loss = 0.3389049221882332\n",
      "80\n",
      "Accuracy = 0.9890814895129815, loss = 0.33889441909639206\n",
      "80\n",
      "Accuracy = 0.989081825444486, loss = 0.3388839922792721\n",
      "80\n",
      "Accuracy = 0.9890821589364154, loss = 0.33887364118295704\n",
      "80\n",
      "Accuracy = 0.9890824900064861, loss = 0.33886336525755334\n",
      "80\n",
      "Accuracy = 0.9890828186722859, loss = 0.3388531639571603\n",
      "80\n",
      "Accuracy = 0.989083144951275, loss = 0.33884303673984306\n",
      "80\n",
      "Accuracy = 0.9890834688607867, loss = 0.33883298306760057\n",
      "80\n",
      "Accuracy = 0.9890837904180285, loss = 0.3388230024063398\n",
      "80\n",
      "Accuracy = 0.9890841096400826, loss = 0.3388130942258464\n",
      "80\n",
      "Accuracy = 0.9890844265439078, loss = 0.3388032579997562\n",
      "80\n",
      "Accuracy = 0.989084741146339, loss = 0.33879349320552754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.989084741146339"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.model(1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5199c494-5878-4291-b97d-7a2e2bc35cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9903091295220195\n"
     ]
    }
   ],
   "source": [
    "pred_y = test.predict(test_x)\n",
    "from sklearn.metrics import r2_score\n",
    "acc = r2_score(test_y, pred_y)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0b423a0-8ed8-4e2b-8ac4-cefdaa5f1b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(pred, act):\n",
    "    total = 0\n",
    "    mean_sL = []\n",
    "    for x in range(0, len(pred)):\n",
    "        mean_s = (pred[x] - act[x])**2\n",
    "        mean_sL.append(mean_s)\n",
    "        total+=mean_s\n",
    "    return (total/len(pred), mean_sL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a05fc5dd-96db-4043-b18a-920ba9c93e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_x, train_y, '.')\n",
    "pred_train = test.predict(train_x)\n",
    "plt.plot(train_x, pred_train, '-', color = 'green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a188dab-1e59-400b-a314-9b4bc6d6104d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy = [0]*80\n",
    "loss, losses = mse(dummy, train_y)\n",
    "plt.plot(train_x, losses, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c90b0-67bf-441a-8740-acbc3aa992a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
